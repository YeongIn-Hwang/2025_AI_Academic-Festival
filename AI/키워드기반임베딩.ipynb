{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "216d6357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"all_places.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    all_places = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d43a2788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html\n",
    "\n",
    "def clean_review(text):\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "\n",
    "    text = html.unescape(text)\n",
    "    text = text.strip()\n",
    "\n",
    "    if len(text) < 3:\n",
    "        return None\n",
    "\n",
    "    if not re.search(\"[가-힣]\", text):  # 한글 없는 외국어 리뷰 제거\n",
    "        return None\n",
    "\n",
    "    text = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", text)  # 반복 문자 정리\n",
    "    text = re.sub(r\"[^\\w\\s가-힣.,!?]\", \"\", text)  # 이모지, 특수문자 제거\n",
    "    text = text[:300]  # 너무 긴 리뷰 자르기\n",
    "\n",
    "    return text if text else None\n",
    "\n",
    "for place in all_places:\n",
    "    original_reviews = place.get(\"reviews\", [])\n",
    "    cleaned_reviews = []\n",
    "\n",
    "    for review in original_reviews:\n",
    "        cleaned = clean_review(review)\n",
    "        if cleaned:\n",
    "            cleaned_reviews.append(cleaned)\n",
    "\n",
    "    place[\"reviews\"] = cleaned_reviews  # ✅ 전처리된 리뷰로 덮어쓰기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9222f9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여행에서의 희망 키워드를 입력하세요! 종료 : 종료\n",
      "여행에서의 비희망 키워드를 입력하세요! 종료 : 종료\n"
     ]
    }
   ],
   "source": [
    "print(\"여행에서의 희망 키워드를 입력하세요! 예 : 전망대 공원 자연\")\n",
    "\"\"\"keyword_hope = []\n",
    "for i in range(10):\n",
    "    keyword = input()\n",
    "    if (keyword == \"종료\"):\n",
    "        break\n",
    "    keyword_hope.append(keyword)\"\"\"\n",
    "\n",
    "print(\"여행에서의 비희망 키워드를 입력하세요! 예 : 시끄러움 혼잡\")\n",
    "\"\"\"keyword_nonhope = []\n",
    "for i in range(10):\n",
    "    keyword = input()\n",
    "    if (keyword == \"종료\"):\n",
    "        break\n",
    "    keyword_nonhope.append(keyword)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fac61e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# ✅ 모델 불러오기 (한 줄로 끝)\n",
    "model = SentenceTransformer(\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\")\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_sbert_embedding(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return np.zeros(model.get_sentence_embedding_dimension())\n",
    "    return model.encode(text, convert_to_numpy=True)\n",
    "\n",
    "def get_sbert_review_vector(reviews):\n",
    "    embeddings = [\n",
    "        get_sbert_embedding(review)\n",
    "        for review in reviews if review.strip()\n",
    "    ]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.get_sentence_embedding_dimension())\n",
    "\n",
    "def get_place_vector_with_name(place, review_weight=1.0, name_weight=0):\n",
    "    reviews = place.get(\"reviews\", [])\n",
    "    name = place.get(\"name\", \"\")\n",
    "\n",
    "    review_vec = get_sbert_review_vector(reviews)\n",
    "    name_vec = get_sbert_embedding(name)\n",
    "\n",
    "    total_weight = review_weight + name_weight\n",
    "    final_vec = (review_weight * review_vec + name_weight * name_vec) / total_weight\n",
    "    return final_vec\n",
    "\n",
    "# 🔁 문맥 벡터 생성 및 저장\n",
    "for place in all_places:\n",
    "    if \"reviews\" in place and \"name\" in place:\n",
    "        place[\"review_vector\"] = get_place_vector_with_name(place)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ff39fcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_hope = [\"루프탑\",\"야경\",\"전망대\",\"고층건물\",\"트랜드 카페\",\"파티\",\"바\",\"주류\",\"공원\",\"한강 뷰\"]\n",
    "keyword_nonhope = [\"벌레\",\"먼지\",\"혼잡\",\"더러움\"]\n",
    "\n",
    "def clean_keyword(text):\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "\n",
    "    text = html.unescape(text)\n",
    "    text = text.strip()\n",
    "\n",
    "    if not re.search(\"[가-힣]\", text):  # 한글 없는 외국어 리뷰 제거\n",
    "        return None\n",
    "\n",
    "    text = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", text)  # 반복 문자 정리\n",
    "    text = re.sub(r\"[^\\w\\s가-힣.,!?]\", \"\", text)  # 이모지, 특수문자 제거\n",
    "    text = text[:300]  # 너무 긴 리뷰 자르기\n",
    "\n",
    "    return text if text else None\n",
    "\n",
    "keyword_hope = [clean_keyword(r) for r in keyword_hope if r]\n",
    "keyword_nonhope = [clean_keyword(r) for r in keyword_nonhope if r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "018252c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hyi1102\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyi1102\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyi1102\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyi1102\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\hyi1102\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['트랜드 카페', '파티', '바', '주류'], ['야경', '전망대', '공원', '한강 뷰'], ['루프탑', '고층건물']]\n",
      "['벌레', '먼지', '혼잡', '더러움']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# 1. 희망 키워드 임베딩\n",
    "hope_embeddings = [get_sbert_embedding(k) for k in keyword_hope if k]\n",
    "\n",
    "# 2. 최적 K 탐색\n",
    "best_k = 2\n",
    "best_score = -1\n",
    "for k in range(2, min(len(hope_embeddings), 6)):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=\"auto\").fit(hope_embeddings)\n",
    "    score = silhouette_score(hope_embeddings, kmeans.labels_)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_k = k\n",
    "\n",
    "# 3. 최적 K로 클러스터링 수행\n",
    "final_kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=\"auto\").fit(hope_embeddings)\n",
    "labels = final_kmeans.labels_\n",
    "\n",
    "clustered_keywords_list = [[] for _ in range(best_k)]\n",
    "cluster_centroids = []\n",
    "\n",
    "# 클러스터 ID별 키워드와 벡터 수집\n",
    "cluster_vectors = [[] for _ in range(best_k)]\n",
    "\n",
    "for keyword, label in zip(keyword_hope, labels):\n",
    "    clustered_keywords_list[label].append(keyword)\n",
    "    cluster_vectors[label].append(get_sbert_embedding(keyword))  # 각 키워드의 벡터 저장\n",
    "\n",
    "# 클러스터별 평균 벡터 계산\n",
    "for vectors in cluster_vectors:\n",
    "    if vectors:\n",
    "        centroid = np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        centroid = np.zeros(model.get_sentence_embedding_dimension())\n",
    "    cluster_centroids.append(centroid)\n",
    "\n",
    "# 결과 저장\n",
    "keyword_hope = clustered_keywords_list  # [[cluster1 키워드들], [cluster2 키워드들], ...]\n",
    "keyword_hope_centroids = cluster_centroids  # [cluster1 벡터, cluster2 벡터, ...]\n",
    "\n",
    "print(keyword_hope)\n",
    "print(keyword_nonhope)\n",
    "\n",
    "# 비선호 키워드 임베딩\n",
    "nonhope_embeddings = [get_sbert_embedding(k) for k in keyword_nonhope if k]\n",
    "\n",
    "# 평균 임베딩 (빈 경우 대비)\n",
    "if nonhope_embeddings:\n",
    "    nonhope_mean_vector = np.mean(nonhope_embeddings, axis=0)\n",
    "else:\n",
    "    nonhope_mean_vector = np.zeros(model.get_sentence_embedding_dimension())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "31421b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def compute_cluster_scores(review_vector, name_vector, cluster_centroids, alpha=0.2):\n",
    "    scores = []\n",
    "    for centroid in cluster_centroids:\n",
    "        # 각 유사도 개별 계산\n",
    "        sim_review = (\n",
    "            cosine_similarity([review_vector], [centroid])[0][0]\n",
    "            if np.linalg.norm(review_vector) > 0 and np.linalg.norm(centroid) > 0\n",
    "            else 0.0\n",
    "        )\n",
    "        sim_name = (\n",
    "            cosine_similarity([name_vector], [centroid])[0][0]\n",
    "            if np.linalg.norm(name_vector) > 0 and np.linalg.norm(centroid) > 0\n",
    "            else 0.0\n",
    "        )\n",
    "        # 이름과 리뷰의 가중합\n",
    "        score = (1 - alpha) * sim_review + alpha * sim_name\n",
    "        scores.append(round(score, 4))\n",
    "    return scores\n",
    "\n",
    "\n",
    "# 모든 장소에 대해 클러스터 점수 부여\n",
    "for place in all_places:\n",
    "    review_vec = place.get(\"review_vector\")\n",
    "    name_vec = get_sbert_embedding(place.get(\"name\", \"\"))\n",
    "    if review_vec is not None:\n",
    "        place[\"cluster_scores\"] = compute_cluster_scores(\n",
    "            review_vec, name_vec, keyword_hope_centroids, alpha=0.2\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "edae500a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 Type: tourist_attraction\n",
      "  - 흑석동공원 | 점수: [0.24, 0.61, 0.23]\n",
      "  - 산기슭공원 | 점수: [0.13, 0.55, 0.22]\n",
      "  - 서래섬 | 점수: [0.19, 0.54, 0.18]\n",
      "  - 마을숲공원 | 점수: [0.21, 0.53, 0.18]\n",
      "  - 원효대교 | 점수: [0.22, 0.52, 0.35]\n",
      "  - 가로공원 | 점수: [0.28, 0.52, 0.29]\n",
      "  - 덕수공원 | 점수: [0.20, 0.48, 0.23]\n",
      "  - 거리공원 | 점수: [0.12, 0.48, 0.12]\n",
      "  - 계남제1근린공원 | 점수: [0.13, 0.48, 0.15]\n",
      "  - 관악산 자연공원 | 점수: [0.12, 0.46, 0.09]\n",
      "\n",
      "📂 Type: cafe\n",
      "  - 로얄호스트 | 점수: [0.49, 0.42, 0.32]\n",
      "  - 스무디킹 영등포타임스퀘어점 | 점수: [0.44, 0.24, 0.16]\n",
      "  - 동작노을카페 | 점수: [0.26, 0.43, 0.25]\n",
      "  - 투썸플레이스 서강대점 | 점수: [0.41, 0.33, 0.19]\n",
      "  - 할리스 커피 구로점 | 점수: [0.40, 0.25, 0.21]\n",
      "  - 투썸플레이스 가산디지털점 | 점수: [0.37, 0.24, 0.14]\n",
      "  - 신촌미플 | 점수: [0.36, 0.30, 0.14]\n",
      "  - bar sting | 점수: [0.35, 0.27, 0.17]\n",
      "  - 비하인드 | 점수: [0.35, 0.23, 0.11]\n",
      "  - 어반트리 | 점수: [0.34, 0.35, 0.22]\n",
      "\n",
      "📂 Type: bar\n",
      "  - 카스타운 | 점수: [0.46, 0.29, 0.18]\n",
      "  - 와바 여의도 직영점 | 점수: [0.43, 0.31, 0.18]\n",
      "  - 생활맥주 구로디지털점 | 점수: [0.42, 0.26, 0.16]\n",
      "  - 치어스영등포구청점 | 점수: [0.42, 0.35, 0.21]\n",
      "  - 통파이브 당산점 | 점수: [0.39, 0.25, 0.18]\n",
      "  - 푸른유월 | 점수: [0.39, 0.34, 0.13]\n",
      "  - 짝태&노가리 | 점수: [0.39, 0.22, 0.16]\n",
      "  - 생활맥주 가산디지털점 | 점수: [0.39, 0.26, 0.15]\n",
      "  - 마르셀 Marcel | 점수: [0.39, 0.19, 0.17]\n",
      "  - 훌랄라숯불바베큐 | 점수: [0.38, 0.23, 0.20]\n",
      "\n",
      "📂 Type: bakery\n",
      "  - 파리바게뜨 여의도점 | 점수: [0.41, 0.32, 0.21]\n",
      "  - 파리바게뜨 구로엘림점 | 점수: [0.39, 0.29, 0.25]\n",
      "  - 파리바게뜨 가산에이스점 | 점수: [0.38, 0.21, 0.22]\n",
      "  - 던킨도너츠 염창점 | 점수: [0.37, 0.13, 0.21]\n",
      "  - 던킨 홍대역점 | 점수: [0.36, 0.25, 0.16]\n",
      "  - 파리크라상 이촌점 | 점수: [0.36, 0.24, 0.19]\n",
      "  - 파리크라상 여의도2호점 | 점수: [0.34, 0.18, 0.16]\n",
      "  - 파리바게뜨 염창점 | 점수: [0.34, 0.17, 0.17]\n",
      "  - 파리바게뜨 난곡사거리점 | 점수: [0.33, 0.22, 0.16]\n",
      "  - 파리바게뜨 영등포대우점 | 점수: [0.33, 0.24, 0.15]\n",
      "\n",
      "📂 Type: restaurant\n",
      "  - 스무디킹 영등포타임스퀘어점 | 점수: [0.44, 0.24, 0.16]\n",
      "  - 본죽 영등포시장로터리점 | 점수: [0.38, 0.23, 0.22]\n",
      "  - 피자나라치킨공주 구로1호점 | 점수: [0.37, 0.22, 0.17]\n",
      "  - 배스킨라빈스 구로고척 | 점수: [0.35, 0.32, 0.23]\n",
      "  - 치킨매니아 영등포역점 | 점수: [0.34, 0.27, 0.14]\n",
      "  - 삿뽀로 목동점 | 점수: [0.32, 0.28, 0.12]\n",
      "  - 하나스시 타임스퀘어점 | 점수: [0.31, 0.13, 0.13]\n",
      "  - 이레 | 점수: [0.29, 0.20, 0.11]\n",
      "  - 한일관 타임스퀘어점 | 점수: [0.28, 0.20, 0.16]\n",
      "  - 피자스쿨 구로1점 | 점수: [0.28, 0.18, 0.09]\n",
      "\n",
      "📂 Type: shopping_mall\n",
      "  - 맥스엔영 | 점수: [0.49, 0.34, 0.28]\n",
      "  - 더슈트하우스 영등포홈플러스 | 점수: [0.34, 0.28, 0.16]\n",
      "  - TOUCH | 점수: [0.34, 0.31, 0.16]\n",
      "  - LUCE | 점수: [0.33, 0.24, 0.21]\n",
      "  - 지오지아 구로점 | 점수: [0.33, 0.22, 0.23]\n",
      "  - YA | 점수: [0.29, 0.15, 0.09]\n",
      "  - 세정 타임스퀘어지점 | 점수: [0.19, 0.26, 0.17]\n",
      "  - 금화주단 | 점수: [0.07, 0.05, 0.07]\n",
      "  - 베베앙슈 | 점수: [0.06, 0.02, 0.06]\n",
      "  - 쿠아 신세계영등포지상A | 점수: [0.06, 0.06, 0.06]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# 타입별 그룹핑\n",
    "type_grouped = defaultdict(list)\n",
    "for place in all_places:\n",
    "    if \"cluster_scores\" in place:\n",
    "        type_grouped[place[\"type\"]].append(place)\n",
    "\n",
    "# 정렬 및 출력\n",
    "for place_type, places in type_grouped.items():\n",
    "    print(f\"\\n📂 Type: {place_type}\")\n",
    "    sorted_places = sorted(places, key=lambda x: max(x[\"cluster_scores\"]), reverse=True)\n",
    "    for p in sorted_places[:10]:  # 상위 10개만 출력\n",
    "        scores_str = \", \".join(f\"{s:.2f}\" for s in p[\"cluster_scores\"])\n",
    "        print(f\"  - {p['name']} | 점수: [{scores_str}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ecce99a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "비선호 키워드 유사도 (타입별 상위 3개씩):\n",
      "\n",
      "🔹 Tourist_Attraction:\n",
      "1. 가로공원\n",
      "비선호 유사도: 0.3953 | 평점: 3.5 | 리뷰 수: 49\n",
      "2. 매화근린공원\n",
      "비선호 유사도: 0.3765 | 평점: 4.1 | 리뷰 수: 29\n",
      "3. 금천교\n",
      "비선호 유사도: 0.3528 | 평점: 3.9 | 리뷰 수: 169\n",
      "4. 방화쌈지공원\n",
      "비선호 유사도: 0.3411 | 평점: 4.1 | 리뷰 수: 167\n",
      "5. 서래섬\n",
      "비선호 유사도: 0.3358 | 평점: 4.4 | 리뷰 수: 762\n",
      "6. 흑석동공원\n",
      "비선호 유사도: 0.3261 | 평점: 4.4 | 리뷰 수: 97\n",
      "7. 덕수공원\n",
      "비선호 유사도: 0.3092 | 평점: 3.7 | 리뷰 수: 51\n",
      "8. 이화여자대학교 자연사박물관\n",
      "비선호 유사도: 0.3009 | 평점: 4.4 | 리뷰 수: 111\n",
      "9. 돈의문(서대문) 터\n",
      "비선호 유사도: 0.2893 | 평점: 3.9 | 리뷰 수: 51\n",
      "10. 부천원미공원\n",
      "비선호 유사도: 0.2827 | 평점: 4.3 | 리뷰 수: 289\n",
      "\n",
      "🔹 Cafe:\n",
      "1. 탐앤탐스 영등포역점\n",
      "비선호 유사도: 0.4440 | 평점: 3.8 | 리뷰 수: 130\n",
      "2. 신촌미플\n",
      "비선호 유사도: 0.4241 | 평점: 4.1 | 리뷰 수: 91\n",
      "3. 어반트리\n",
      "비선호 유사도: 0.4031 | 평점: 4 | 리뷰 수: 1\n",
      "4. 커피빈 홍대역점\n",
      "비선호 유사도: 0.3678 | 평점: 4 | 리뷰 수: 556\n",
      "5. 아리스타커피 등촌점\n",
      "비선호 유사도: 0.3416 | 평점: 3.7 | 리뷰 수: 14\n",
      "6. 비하인드\n",
      "비선호 유사도: 0.3274 | 평점: 4.3 | 리뷰 수: 63\n",
      "7. 이디야커피 서여의도점\n",
      "비선호 유사도: 0.3260 | 평점: 4 | 리뷰 수: 116\n",
      "8. 할리스 커피 구로점\n",
      "비선호 유사도: 0.3207 | 평점: 3.7 | 리뷰 수: 88\n",
      "9. 핸드픽트호텔\n",
      "비선호 유사도: 0.3183 | 평점: 4.1 | 리뷰 수: 599\n",
      "10. 파스쿠찌보라매공원점\n",
      "비선호 유사도: 0.3131 | 평점: 4 | 리뷰 수: 203\n",
      "\n",
      "🔹 Bar:\n",
      "1. 비닐하우스\n",
      "비선호 유사도: 0.5079 | 평점: 4.1 | 리뷰 수: 148\n",
      "2. 푸른유월\n",
      "비선호 유사도: 0.3965 | 평점: 4.2 | 리뷰 수: 5\n",
      "3. 치치 홍대점\n",
      "비선호 유사도: 0.3845 | 평점: 4.2 | 리뷰 수: 81\n",
      "4. 이화주막\n",
      "비선호 유사도: 0.3712 | 평점: 3.5 | 리뷰 수: 2\n",
      "5. MAG Live Club\n",
      "비선호 유사도: 0.3710 | 평점: 3.7 | 리뷰 수: 3\n",
      "6. 짝태&노가리\n",
      "비선호 유사도: 0.3609 | 평점: 3.9 | 리뷰 수: 15\n",
      "7. 와라와라\n",
      "비선호 유사도: 0.3600 | 평점: 3.6 | 리뷰 수: 114\n",
      "8. 와바 영등포 직영점\n",
      "비선호 유사도: 0.3549 | 평점: 4.5 | 리뷰 수: 2\n",
      "9. 또래오래\n",
      "비선호 유사도: 0.3232 | 평점: 4 | 리뷰 수: 4\n",
      "10. 투다리 구로역점\n",
      "비선호 유사도: 0.3213 | 평점: 4.1 | 리뷰 수: 22\n",
      "\n",
      "🔹 Bakery:\n",
      "1. 던킨 홍대역점\n",
      "비선호 유사도: 0.3713 | 평점: 3.9 | 리뷰 수: 158\n",
      "2. 파리크라상 여의도2호점\n",
      "비선호 유사도: 0.3304 | 평점: 4 | 리뷰 수: 309\n",
      "3. 파리바게뜨 오목교역점\n",
      "비선호 유사도: 0.3220 | 평점: 4 | 리뷰 수: 13\n",
      "4. 파리바게뜨 여의도점\n",
      "비선호 유사도: 0.3211 | 평점: 3.9 | 리뷰 수: 25\n",
      "5. 빵굼터 대림동점\n",
      "비선호 유사도: 0.3209 | 평점: 4 | 리뷰 수: 1\n",
      "6. 파리바게뜨 구로디지털점\n",
      "비선호 유사도: 0.3085 | 평점: 3.9 | 리뷰 수: 14\n",
      "7. 던킨도너츠 염창점\n",
      "비선호 유사도: 0.3079 | 평점: 3.6 | 리뷰 수: 23\n",
      "8. 파리바게뜨 금천구청역점\n",
      "비선호 유사도: 0.3008 | 평점: 3.7 | 리뷰 수: 15\n",
      "9. 던킨도너츠 구로태평양물산점\n",
      "비선호 유사도: 0.2919 | 평점: 3.7 | 리뷰 수: 59\n",
      "10. 파리바게뜨 가산에이스점\n",
      "비선호 유사도: 0.2918 | 평점: 3.6 | 리뷰 수: 9\n",
      "\n",
      "🔹 Restaurant:\n",
      "1. 본죽 영등포시장로터리점\n",
      "비선호 유사도: 0.3665 | 평점: 3.5 | 리뷰 수: 11\n",
      "2. 이레\n",
      "비선호 유사도: 0.3315 | 평점: 4.8 | 리뷰 수: 12\n",
      "3. 배스킨라빈스 구로고척\n",
      "비선호 유사도: 0.3303 | 평점: 4.4 | 리뷰 수: 50\n",
      "4. 하나스시 타임스퀘어점\n",
      "비선호 유사도: 0.3211 | 평점: 3.8 | 리뷰 수: 4\n",
      "5. 핸드픽트호텔\n",
      "비선호 유사도: 0.3183 | 평점: 4.1 | 리뷰 수: 599\n",
      "6. 롯데리아 구로시장점\n",
      "비선호 유사도: 0.3129 | 평점: 3.6 | 리뷰 수: 321\n",
      "7. 한일관 타임스퀘어점\n",
      "비선호 유사도: 0.2942 | 평점: 4 | 리뷰 수: 409\n",
      "8. 피자나라치킨공주 구로1호점\n",
      "비선호 유사도: 0.2681 | 평점: 3.5 | 리뷰 수: 15\n",
      "9. 피자스쿨 영등포남부역점\n",
      "비선호 유사도: 0.2624 | 평점: 4.5 | 리뷰 수: 72\n",
      "10. 스무디킹 영등포타임스퀘어점\n",
      "비선호 유사도: 0.2613 | 평점: 3.9 | 리뷰 수: 10\n",
      "\n",
      "🔹 Shopping_Mall:\n",
      "1. 지오지아 구로점\n",
      "비선호 유사도: 0.3878 | 평점: 3.7 | 리뷰 수: 7\n",
      "2. LUCE\n",
      "비선호 유사도: 0.3819 | 평점: 3.5 | 리뷰 수: 6\n",
      "3. TOUCH\n",
      "비선호 유사도: 0.2929 | 평점: 3.6 | 리뷰 수: 5\n",
      "4. 토트라\n",
      "비선호 유사도: 0.2928 | 평점: 4 | 리뷰 수: 1\n",
      "5. YA\n",
      "비선호 유사도: 0.2805 | 평점: 5 | 리뷰 수: 1\n",
      "6. 맥스엔영\n",
      "비선호 유사도: 0.2804 | 평점: 3.8 | 리뷰 수: 13\n",
      "7. 세정 타임스퀘어지점\n",
      "비선호 유사도: 0.2637 | 평점: 4 | 리뷰 수: 3\n",
      "8. 금화주단\n",
      "비선호 유사도: 0.2628 | 평점: 3.8 | 리뷰 수: 4\n",
      "9. 더슈트하우스 영등포홈플러스\n",
      "비선호 유사도: 0.2534 | 평점: 3.6 | 리뷰 수: 27\n",
      "10. 천사들의합창\n",
      "비선호 유사도: 0.2291 | 평점: 4.3 | 리뷰 수: 3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "\n",
    "# 이름과 리뷰를 함께 고려한 벡터 (가중치 조절 가능)\n",
    "def get_combined_place_vector(place, review_weight=1.0, name_weight=1.0):\n",
    "    review_vec = place.get(\"review_vector\", np.zeros(model.get_sentence_embedding_dimension()))\n",
    "    name_vec = get_sbert_embedding(place.get(\"name\", \"\"))\n",
    "    \n",
    "    if np.linalg.norm(review_vec) == 0 and np.linalg.norm(name_vec) == 0:\n",
    "        return np.zeros(model.get_sentence_embedding_dimension())\n",
    "    \n",
    "    total_weight = review_weight + name_weight\n",
    "    return (review_weight * review_vec + name_weight * name_vec) / total_weight\n",
    "\n",
    "# 장소별 비선호 유사도 계산 (이름 포함)\n",
    "for place in all_places:\n",
    "    combined_vec = get_combined_place_vector(place, review_weight=1.0, name_weight=1.0)\n",
    "    if np.linalg.norm(combined_vec) > 0 and np.linalg.norm(nonhope_mean_vector) > 0:\n",
    "        score = cosine_similarity([combined_vec], [nonhope_mean_vector])[0][0]\n",
    "        place[\"nonhope_score\"] = round(score, 4)\n",
    "    else:\n",
    "        place[\"nonhope_score\"] = 0.0\n",
    "\n",
    "# 타입별로 그룹화 및 출력\n",
    "type_to_places = defaultdict(list)\n",
    "for place in all_places:\n",
    "    type_to_places[place[\"type\"]].append(place)\n",
    "\n",
    "print(\"\\n비선호 키워드 유사도 (타입별 상위 3개씩):\")\n",
    "for place_type, places in type_to_places.items():\n",
    "    print(f\"\\n🔹 {place_type.title()}:\")\n",
    "    top_places = sorted(places, key=lambda x: x[\"nonhope_score\"], reverse=True)[:10]\n",
    "    for i, place in enumerate(top_places, 1):\n",
    "        print(f\"{i}. {place['name']}\")\n",
    "        print(f\"비선호 유사도: {place['nonhope_score']:.4f} | 평점: {place['rating']} | 리뷰 수: {place['user_ratings_total']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "43834683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def convert_place_for_json(place):\n",
    "    p = place.copy()\n",
    "    for key in [\"review_vector\", \"name_vector\"]:\n",
    "        if isinstance(p.get(key), np.ndarray):\n",
    "            p[key] = p[key].tolist()\n",
    "    if \"cluster_scores\" in p:\n",
    "        p[\"cluster_scores\"] = list(map(float, p[\"cluster_scores\"]))\n",
    "    if \"nonhope_score\" in p:\n",
    "        p[\"nonhope_score\"] = float(p[\"nonhope_score\"])\n",
    "    return p\n",
    "\n",
    "json_ready = [convert_place_for_json(p) for p in all_places]\n",
    "\n",
    "with open(\"all_places_embedding.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json_ready, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ 저장 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3521109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"all_places_embedding.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    all_places = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11d4b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from datetime import time, datetime, timedelta\n",
    "\n",
    "# 유클리드 기반 거리 계산 함수\n",
    "def euclidean(lat1, lon1, lat2, lon2):\n",
    "    return math.sqrt((lat1 - lat2) ** 2 + (lon1 - lon2) ** 2)\n",
    "\n",
    "# 거리 계산 함수\n",
    "def compute_distance_matrix(places): \n",
    "    n = len(places)\n",
    "    matrix = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                matrix[i][j] = euclidean(\n",
    "                    places[i]['lat'], places[i]['lng'],\n",
    "                    places[j]['lat'], places[j]['lng']\n",
    "                )\n",
    "    return matrix\n",
    "\n",
    "# 분단위 시간 차이 계산 함수\n",
    "def time_diff_minutes(t1, t2):\n",
    "    dt1 = datetime.combine(datetime.today(), t1)\n",
    "    dt2 = datetime.combine(datetime.today(), t2)\n",
    "    return abs((dt1 - dt2).total_seconds() / 60)\n",
    "\n",
    "time_table = []\n",
    "\n",
    "class ScheduleItem:\n",
    "    def __init__(self, title, start, end, place_type):\n",
    "        self.title = title\n",
    "        self.start = start  \n",
    "        self.end = end     \n",
    "        self.place_type = place_type\n",
    "\n",
    "# 명소 제약 조건 대입\n",
    "def get_constraints(base_mode=\"명소 중심\"):\n",
    "    constraints = {\n",
    "        \"must_visit_attraction_every_minutes\": 180,  # 3시간 : 마지막 명소 방문 후 일정 시간이 지나면 반드시 새로운 명소를 추천해야 한다는 제약\n",
    "        \"attraction_required\": True, # 하루 일정에 명소가 반드시 포함되어야 하는지 여부\n",
    "\n",
    "        \"min_minutes_between_meals\": 360,  # 6시간 : 식사 후 식사를 반드시 해야하는 제약 여부\n",
    "        \"require_meal_after_threshold\": True, # 식사를 하지 않고 일정 시간이 지나면, 다음 일정으로 반드시 식사를 포함해야 한다는 조건\n",
    "        \"dont_eat_meal\": 180, #식사 후 지나가야하는 시간 여부\n",
    "\n",
    "        \"department_store_required_interval\": None, # 일정이 특정 시간(분 단위) 이상 지날 때마다 백화점이나 쇼핑몰을 꼭 일정에 넣어야 한다는 제약 조건\n",
    "\n",
    "        \"allow_multiple_cafes\": False # 하루 일정에 카페(또는 유사 장소: 빵집 등)를 연속으로 포함하는 것을 허용할지 여부\n",
    "    }\n",
    "    # 추가 선택 옵션 반영\n",
    "    if base_mode ==\"식사 중심\": # 명소 필수 제거하고 식사 가게 제약을 3시간으로 감소\n",
    "        constraints[\"attraction_required\"] = False\n",
    "        constraints[\"min_minutes_between_meals\"] = 180\n",
    "\n",
    "    if base_mode ==\"카페, 빵집 중심\": # 식사 필수 조건 제거하고 명소 필수 제거, 카페연속 허용\n",
    "        constraints[\"require_meal_after_threshold\"] = False\n",
    "        constraints[\"attraction_required\"] = False\n",
    "        constraints[\"allow_multiple_cafes\"] = True\n",
    "\n",
    "    if base_mode ==\"쇼핑 중심\": # 명소조건 제거 및 백화점 개수 제한 해제\n",
    "        constraints[\"department_store_required_interval\"] = 180  # 3시간마다 쇼핑\n",
    "        constraints[\"attraction_required\"] = False\n",
    "\n",
    "    return constraints\n",
    "\n",
    "# 인덱스 기준 지난 최대 시간 반환\n",
    "def get_elapsed_minutes_since_last_type(place_type, time_table, idx):\n",
    "    \"\"\"현재 인덱스 기준, 해당 타입(place_type)의 마지막 방문으로부터 경과한 시간(분)을 반환\"\"\"\n",
    "    current_start = time_table[idx].start\n",
    "\n",
    "    for i in range(idx - 1, -1, -1):  # 현재 index 이전만 탐색\n",
    "        if time_table[i].place_type == place_type:\n",
    "            last_end = time_table[i].end\n",
    "            return time_diff_minutes(last_end, current_start)\n",
    "\n",
    "    return None  # 해당 타입이 아예 없었던 경우\n",
    "\n",
    "# 타입 선택 함수\n",
    "def select_allowed_types(time_table, base_mode, idx):\n",
    "    allowed_types = ['tourist_attraction', 'cafe', 'restaurant', 'bakery', 'bar', 'shopping_mall']\n",
    "\n",
    "    constraints = get_constraints(base_mode)\n",
    "\n",
    "    if constraints[\"attraction_required\"] == True:\n",
    "        if get_elapsed_minutes_since_last_type('tourist_attraction', time_table, idx)>=constraints[\"must_visit_attraction_every_minutes\"]:\n",
    "            allowed_types = ['tourist_attraction']\n",
    "            return allowed_types\n",
    "    \n",
    "    if constraints[\"require_meal_after_threshold\"] == True:\n",
    "        if get_elapsed_minutes_since_last_type('restaurant', time_table, idx)<=constraints[\"dont_eat_meal\"]:\n",
    "            allowed_types.remove(\"restaurant\")\n",
    "        if get_elapsed_minutes_since_last_type('restaurant', time_table, idx)>=constraints[\"min_minutes_between_meals\"]:\n",
    "            allowed_types = ['restaurant']\n",
    "            return allowed_types\n",
    "    \n",
    "    if constraints[\"department_store_required_interval\"] != None:\n",
    "        if get_elapsed_minutes_since_last_type('shopping_mall', time_table, idx)<=constraints[\"department_store_required_interval\"]:\n",
    "            allowed_types = ['shopping_mall']\n",
    "            return allowed_types\n",
    "    \n",
    "    if constraints[\"allow_multiple_cafes\"] == False:\n",
    "        if time_table[idx-1].place_type == \"cafe\" or time_table[idx-1].place_type == \"bakery\":\n",
    "            for t in [\"cafe\", \"bakery\"]:\n",
    "                allowed_types.remove(t)\n",
    "    \n",
    "    return allowed_types\n",
    "\n",
    "def generate_empty_slots(time_table, day_start=time(9, 0), day_end=time(23, 59)):\n",
    "    empty_slots = []\n",
    "\n",
    "    def to_datetime(t):\n",
    "        return datetime.combine(datetime.today(), t)\n",
    "\n",
    "    # 정렬된 타임테이블로 가정\n",
    "    sorted_table = sorted(time_table, key=lambda x: x.start)\n",
    "\n",
    "    # Step 1. 처음 ~ 첫 일정 전 구간\n",
    "    if not sorted_table or sorted_table[0].start > day_start:\n",
    "        empty_slots += split_empty_range(day_start, sorted_table[0].start if sorted_table else day_end)\n",
    "\n",
    "    # Step 2. 일정 사이 빈 공간 찾기\n",
    "    for i in range(len(sorted_table) - 1):\n",
    "        current_end = sorted_table[i].end\n",
    "        next_start = sorted_table[i + 1].start\n",
    "        if current_end < next_start:\n",
    "            empty_slots += split_empty_range(current_end, next_start)\n",
    "\n",
    "    # Step 3. 마지막 일정 ~ 하루 끝\n",
    "    if sorted_table and sorted_table[-1].end < day_end:\n",
    "        empty_slots += split_empty_range(sorted_table[-1].end, day_end)\n",
    "\n",
    "    return empty_slots\n",
    "\n",
    "def split_empty_range(start_time, end_time):\n",
    "    slots = []\n",
    "    dt_start = datetime.combine(datetime.today(), start_time)\n",
    "    dt_end = datetime.combine(datetime.today(), end_time)\n",
    "    gap_minutes = int((dt_end - dt_start).total_seconds() // 60)\n",
    "\n",
    "    if gap_minutes < 90:\n",
    "        return []  # 너무 짧은 공간은 무시\n",
    "\n",
    "    elif gap_minutes < 180:\n",
    "        # 하나로 통짜 슬롯\n",
    "        slots.append(ScheduleItem(None, start_time, end_time, None))\n",
    "    else:\n",
    "        # 90분 단위로 쪼갬\n",
    "        dt_cursor = dt_start\n",
    "        while (dt_end - dt_cursor).total_seconds() >= 90 * 60:\n",
    "            dt_next = dt_cursor + timedelta(minutes=90)\n",
    "            slots.append(ScheduleItem(None, dt_cursor.time(), dt_next.time(), None))\n",
    "            dt_cursor = dt_next\n",
    "\n",
    "        # 남은 시간 (예: 2시간 30분에서 마지막 30분)\n",
    "        if dt_cursor < dt_end:\n",
    "            slots.append(ScheduleItem(None, dt_cursor.time(), dt_end.time(), None))\n",
    "\n",
    "    return slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cacbe8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:00 - 11:30 | 경복궁 | tourist_attraction\n",
      "11:30 - 13:00 | (빈 슬롯) | -\n",
      "13:00 - 14:00 | 점심 | restaurant\n",
      "14:00 - 16:00 | (빈 슬롯) | -\n",
      "16:00 - 18:00 | N타워 | tourist_attraction\n",
      "18:00 - 19:30 | (빈 슬롯) | -\n",
      "19:30 - 21:00 | (빈 슬롯) | -\n",
      "21:00 - 22:30 | (빈 슬롯) | -\n",
      "22:30 - 23:59 | (빈 슬롯) | -\n"
     ]
    }
   ],
   "source": [
    "time_table = [\n",
    "    ScheduleItem(\"경복궁\", time(10, 0), time(11, 30), \"tourist_attraction\"),\n",
    "    ScheduleItem(\"점심\", time(13, 0), time(14, 0), \"restaurant\"),\n",
    "    ScheduleItem(\"N타워\", time(16, 0), time(18, 0), \"tourist_attraction\"),\n",
    "]\n",
    "\n",
    "# 1. 빈 슬롯 생성\n",
    "empty_slots = generate_empty_slots(time_table)\n",
    "\n",
    "# 2. 실제 일정과 빈 슬롯을 합침\n",
    "full_schedule = time_table + empty_slots\n",
    "\n",
    "# 3. 시작 시간 기준으로 정렬\n",
    "full_schedule.sort(key=lambda x: x.start)\n",
    "\n",
    "# 4. 출력\n",
    "for item in full_schedule:\n",
    "    title = item.title if item.title else \"(빈 슬롯)\"\n",
    "    type_ = item.place_type if item.place_type else \"-\"\n",
    "    print(f\"{item.start.strftime('%H:%M')} - {item.end.strftime('%H:%M')} | {title} | {type_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8a10c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fer-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
