{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5690e8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"AIzaSyBEl50H0xV7SnyNwcc0Yo-Ru-iiTXTBePc\"\n",
    "\n",
    "PLACE_TYPES = [\n",
    "    \"tourist_attraction\",\n",
    "    \"cafe\",\n",
    "    \"bar\",\n",
    "    \"bakery\",\n",
    "    \"restaurant\",\n",
    "    \"shopping_mall\",\n",
    "]\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import requests\n",
    "import math\n",
    "import re\n",
    "import html\n",
    "import time as tm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from collections import defaultdict\n",
    "from datetime import time, datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22784cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” 'ì‹ ë„ë¦¼' ì£¼ë³€ ê²€ìƒ‰ ê²°ê³¼:\n",
      "\n",
      "ğŸ”¹ Tourist_Attraction (ì‹ ë¢°ë„ ìƒìœ„ 20ê°œ)\n",
      "\n",
      "ğŸ”¹ Cafe (ì‹ ë¢°ë„ ìƒìœ„ 20ê°œ)\n",
      "\n",
      "ğŸ”¹ Bar (ì‹ ë¢°ë„ ìƒìœ„ 20ê°œ)\n",
      "\n",
      "ğŸ”¹ Bakery (ì‹ ë¢°ë„ ìƒìœ„ 20ê°œ)\n",
      "\n",
      "ğŸ”¹ Restaurant (ì‹ ë¢°ë„ ìƒìœ„ 20ê°œ)\n",
      "\n",
      "ğŸ”¹ Shopping_Mall (ì‹ ë¢°ë„ ìƒìœ„ 20ê°œ)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ì‚¬ìš©ì ì…ë ¥\n",
    "query = input(\"ì–´ëŠ ì§€ì—­ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì—¬í–‰ ê²½ë¡œë¥¼ ì§œë“œë¦´ê¹Œìš”? (ì˜ˆ: ê²½ë³µê¶, ê°•ë‚¨ì—­): \\n\")\n",
    "method = int(input(\"ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ì—¬í–‰í•˜ì‹œë‚˜ìš”? 1 : ë„ë³´ 2 : ëŒ€ì¤‘êµí†µ, 3 : ì§ì ‘ ìš´ì „\\n\"))\n",
    "radius = {1: \"3000\", 2: \"15000\", 3: \"30000\"}.get(method)\n",
    "\n",
    "# ì§€ì˜¤ì½”ë”©\n",
    "geo_url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "geo_params = {\n",
    "    \"address\": query,\n",
    "    \"key\": API_KEY,\n",
    "    \"language\": \"ko\"\n",
    "}\n",
    "geo_res = requests.get(geo_url, params=geo_params).json()\n",
    "\n",
    "if not geo_res[\"results\"]:\n",
    "    print(\"ìœ„ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ ì£¼ì„¸ìš”.\")\n",
    "    exit()\n",
    "\n",
    "location = geo_res[\"results\"][0][\"geometry\"][\"location\"]\n",
    "lat, lng = location[\"lat\"], location[\"lng\"]\n",
    "\n",
    "def compute_review_weight_log(reviews, max_reviews=1000):\n",
    "    if reviews is None or reviews <= 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # 1 ì´ìƒì´ì–´ì•¼ ë¡œê·¸ ê³„ì‚° ê°€ëŠ¥\n",
    "    log_base = 10\n",
    "    normalized = math.log(min(reviews, max_reviews), log_base) / math.log(max_reviews, log_base)\n",
    "    return round(normalized, 4)\n",
    "\n",
    "# ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜\n",
    "def compute_trust_score(rating, reviews, latest_review_time_str=\"\"):\n",
    "    if rating is None or reviews is None:\n",
    "        return 0.0\n",
    "\n",
    "    # ë¡œê·¸ ê¸°ë°˜ ì‹ ë¢°ë„ ê³„ì‚°\n",
    "    review_weight = compute_review_weight_log(reviews, max_reviews=1000)\n",
    "\n",
    "    # ìµœì‹ ì„± ë³´ë„ˆìŠ¤\n",
    "    bonus_ratio = 0.0\n",
    "    try:\n",
    "        if \"day\" in latest_review_time_str or \"week\" in latest_review_time_str:\n",
    "            bonus_ratio = 0.10\n",
    "        elif \"month\" in latest_review_time_str:\n",
    "            months = int(latest_review_time_str.split()[0])\n",
    "            if months <= 1:\n",
    "                bonus_ratio = 0.10\n",
    "            elif months <= 6:\n",
    "                bonus_ratio = 0.05\n",
    "    except:\n",
    "        bonus_ratio = 0.0\n",
    "\n",
    "    trust_score = rating * review_weight * (1 + bonus_ratio)\n",
    "    return round(min(trust_score, 5.0), 4)\n",
    "\n",
    "# ì¥ì†Œ ê²€ìƒ‰ (ë¦¬ë·°ëŠ” ì•ˆ ë°›ìŒ)\n",
    "def search_places_basic(place_type):\n",
    "    url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
    "    params = {\n",
    "        \"location\": f\"{lat},{lng}\",\n",
    "        \"radius\": radius,\n",
    "        \"type\": place_type,\n",
    "        \"language\": \"ko\",\n",
    "        \"key\": API_KEY\n",
    "    }\n",
    "\n",
    "    candidates = []\n",
    "    for _ in range(2):  # ìµœëŒ€ 2í˜ì´ì§€\n",
    "        res = requests.get(url, params=params).json()\n",
    "        results = res.get(\"results\", [])\n",
    "        for place in results:\n",
    "            rating = place.get(\"rating\", 0)\n",
    "            user_ratings_total = place.get(\"user_ratings_total\", 0)\n",
    "            if user_ratings_total < 1 or rating < 3.5:\n",
    "                continue\n",
    "            location = place.get(\"geometry\", {}).get(\"location\", {})\n",
    "            place_lat = location.get(\"lat\")\n",
    "            place_lng = location.get(\"lng\")\n",
    "            candidates.append({\n",
    "                \"place_id\": place.get(\"place_id\"),\n",
    "                \"name\": place.get(\"name\"),\n",
    "                \"vicinity\": place.get(\"vicinity\", \"ì£¼ì†Œ ì—†ìŒ\"),\n",
    "                \"rating\": rating,\n",
    "                \"user_ratings_total\": user_ratings_total,\n",
    "                \"trust_score\": compute_trust_score(rating, user_ratings_total),\n",
    "                \"type\": place_type,\n",
    "                \"lat\": place_lat,\n",
    "                \"lng\": place_lng\n",
    "            })\n",
    "        token = res.get(\"next_page_token\")\n",
    "        if not token:\n",
    "            break\n",
    "        tm.sleep(2)\n",
    "        params = {\"pagetoken\": token, \"key\": API_KEY, \"language\": \"ko\"}\n",
    "    # ìƒìœ„ 20ê°œë§Œ ë°˜í™˜\n",
    "    candidates.sort(key=lambda x: x[\"trust_score\"], reverse=True)\n",
    "    return candidates[:40]\n",
    "\n",
    "# ë¦¬ë·° ìš”ì²­ í•¨ìˆ˜\n",
    "def get_reviews_and_business_info(place_id):\n",
    "    url = \"https://maps.googleapis.com/maps/api/place/details/json\"\n",
    "    params = {\n",
    "        \"place_id\": place_id,\n",
    "        \"fields\": \"review,business_status,opening_hours\",\n",
    "        \"language\": \"ko\",\n",
    "        \"key\": API_KEY\n",
    "    }\n",
    "    res = requests.get(url, params=params).json()\n",
    "    result = res.get(\"result\", {})\n",
    "\n",
    "    # ë¦¬ë·°\n",
    "    reviews = result.get(\"reviews\", [])\n",
    "    texts = [r[\"text\"] for r in reviews[:5]]\n",
    "    latest_time = reviews[0][\"relative_time_description\"] if reviews else \"\"\n",
    "\n",
    "    # ì˜ì—… ìƒíƒœ\n",
    "    business_status = result.get(\"business_status\", \"UNKNOWN\")\n",
    "\n",
    "    # ìš´ì˜ ì‹œê°„\n",
    "    opening_hours = result.get(\"opening_hours\", {})\n",
    "    open_now = opening_hours.get(\"open_now\", None)\n",
    "    weekday_text = opening_hours.get(\"weekday_text\", [])\n",
    "\n",
    "    return texts, latest_time, business_status, open_now, weekday_text\n",
    "\n",
    "# ì „ì²´ ì¥ì†Œ ëˆ„ì  ì €ì¥\n",
    "all_places = []\n",
    "\n",
    "print(f\"\\n'{query}' ì£¼ë³€ ê²€ìƒ‰ ê²°ê³¼:\")\n",
    "\n",
    "for place_type in PLACE_TYPES:\n",
    "    top_places = search_places_basic(place_type)\n",
    "    print(f\"\\n{place_type.title()} (ì‹ ë¢°ë„ ìƒìœ„ 20ê°œ)\")\n",
    "    for place in top_places:\n",
    "        reviews, latest_time, biz_status, open_now, weekday_hours = get_reviews_and_business_info(place[\"place_id\"])\n",
    "        place[\"reviews\"] = reviews\n",
    "        place[\"trust_score\"] = compute_trust_score(place[\"rating\"], place[\"user_ratings_total\"], latest_time)\n",
    "        place[\"business_status\"] = biz_status\n",
    "        place[\"open_now\"] = open_now\n",
    "        place[\"weekday_text\"] = weekday_hours\n",
    "        all_places.append(place)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b433bdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_places.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_places, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "216d6357",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_places.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    all_places = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43a2788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(text):\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "\n",
    "    text = html.unescape(text)\n",
    "    text = text.strip()\n",
    "\n",
    "    if len(text) < 3:\n",
    "        return None\n",
    "\n",
    "    if not re.search(\"[ê°€-í£]\", text):  # í•œê¸€ ì—†ëŠ” ì™¸êµ­ì–´ ë¦¬ë·° ì œê±°\n",
    "        return None\n",
    "\n",
    "    text = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", text)  # ë°˜ë³µ ë¬¸ì ì •ë¦¬\n",
    "    text = re.sub(r\"[^\\w\\sê°€-í£.,!?]\", \"\", text)  # ì´ëª¨ì§€, íŠ¹ìˆ˜ë¬¸ì ì œê±°\n",
    "    text = text[:300]  # ë„ˆë¬´ ê¸´ ë¦¬ë·° ìë¥´ê¸°\n",
    "\n",
    "    return text if text else None\n",
    "\n",
    "for place in all_places:\n",
    "    original_reviews = place.get(\"reviews\", [])\n",
    "    cleaned_reviews = []\n",
    "\n",
    "    for review in original_reviews:\n",
    "        cleaned = clean_review(review)\n",
    "        if cleaned:\n",
    "            cleaned_reviews.append(cleaned)\n",
    "\n",
    "    place[\"reviews\"] = cleaned_reviews  # ì „ì²˜ë¦¬ëœ ë¦¬ë·°ë¡œ ë®ì–´ì“°ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9222f9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì—¬í–‰ì—ì„œì˜ í¬ë§ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”! ì˜ˆ : ì „ë§ëŒ€ ê³µì› ìì—°\n",
      "ì—¬í–‰ì—ì„œì˜ ë¹„í¬ë§ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”! ì˜ˆ : ì‹œë„ëŸ¬ì›€ í˜¼ì¡\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'keyword_nonhope = []\\nfor i in range(10):\\n    keyword = input()\\n    if (keyword == \"ì¢…ë£Œ\"):\\n        break\\n    keyword_nonhope.append(keyword)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"ì—¬í–‰ì—ì„œì˜ í¬ë§ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”! ì˜ˆ : ì „ë§ëŒ€ ê³µì› ìì—°\")\n",
    "\"\"\"keyword_hope = []\n",
    "for i in range(5):\n",
    "    keyword = input()\n",
    "    if (keyword == \"ì¢…ë£Œ\"):\n",
    "        break\n",
    "    keyword_hope.append(keyword)\"\"\"\n",
    "\n",
    "print(\"ì—¬í–‰ì—ì„œì˜ ë¹„í¬ë§ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”! ì˜ˆ : ì‹œë„ëŸ¬ì›€ í˜¼ì¡\")\n",
    "\"\"\"keyword_nonhope = []\n",
    "for i in range(5):\n",
    "    keyword = input()\n",
    "    if (keyword == \"ì¢…ë£Œ\"):\n",
    "        break\n",
    "    keyword_nonhope.append(keyword)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fac61e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (í•œ ì¤„ë¡œ ë)\n",
    "model = SentenceTransformer(\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\")\n",
    "\n",
    "def get_sbert_embedding(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return np.zeros(model.get_sentence_embedding_dimension())\n",
    "    return model.encode(text, convert_to_numpy=True)\n",
    "\n",
    "def get_sbert_review_vector(reviews):\n",
    "    embeddings = [\n",
    "        get_sbert_embedding(review)\n",
    "        for review in reviews if review.strip()\n",
    "    ]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.get_sentence_embedding_dimension())\n",
    "\n",
    "def get_place_vector_with_name(place, review_weight=1.0, name_weight=0):\n",
    "    reviews = place.get(\"reviews\", [])\n",
    "    name = place.get(\"name\", \"\")\n",
    "\n",
    "    review_vec = get_sbert_review_vector(reviews)\n",
    "    name_vec = get_sbert_embedding(name)\n",
    "\n",
    "    total_weight = review_weight + name_weight\n",
    "    final_vec = (review_weight * review_vec + name_weight * name_vec) / total_weight\n",
    "    return final_vec\n",
    "\n",
    "# ë¬¸ë§¥ ë²¡í„° ìƒì„± ë° ì €ì¥\n",
    "for place in all_places:\n",
    "    if \"reviews\" in place and \"name\" in place:\n",
    "        place[\"review_vector\"] = get_place_vector_with_name(place)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff39fcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_hope = [\"ë£¨í”„íƒ‘\",\"ì•¼ê²½\",\"ì „ë§ëŒ€\",\"ê³ ì¸µê±´ë¬¼\",\"í•œê°• ë·°\"]\n",
    "keyword_nonhope = [\"ë²Œë ˆ\",\"ë¨¼ì§€\",\"í˜¼ì¡\",\"ë”ëŸ¬ì›€\",\"ê³µì›\"]\n",
    "\n",
    "def clean_keyword(text):\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "\n",
    "    text = html.unescape(text)\n",
    "    text = text.strip()\n",
    "\n",
    "    if not re.search(\"[ê°€-í£]\", text):  # í•œê¸€ ì—†ëŠ” ì™¸êµ­ì–´ ë¦¬ë·° ì œê±°\n",
    "        return None\n",
    "\n",
    "    text = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", text)  # ë°˜ë³µ ë¬¸ì ì •ë¦¬\n",
    "    text = re.sub(r\"[^\\w\\sê°€-í£.,!?]\", \"\", text)  # ì´ëª¨ì§€, íŠ¹ìˆ˜ë¬¸ì ì œê±°\n",
    "    text = text[:300]  # ë„ˆë¬´ ê¸´ í‚¤ì›Œë“œ ìë¥´ê¸°\n",
    "\n",
    "    return text if text else None\n",
    "\n",
    "keyword_hope = [clean_keyword(r) for r in keyword_hope if r]\n",
    "keyword_nonhope = [clean_keyword(r) for r in keyword_nonhope if r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edae500a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‚ Type: tourist_attraction\n",
      "  - ì›íš¨ëŒ€êµ | ì ìˆ˜: 0.5385\n",
      "  - ê³ ì‚°ìêµ | ì ìˆ˜: 0.4285\n",
      "  - ê¸ˆì²œêµ | ì ìˆ˜: 0.4212\n",
      "  - Nì„œìš¸íƒ€ì›Œ | ì ìˆ˜: 0.4029\n",
      "  - ì§„ê´€ê·¼ë¦°ê³µì› | ì ìˆ˜: 0.4008\n",
      "  - ë°±ë ¨ê·¼ë¦°ê³µì› | ì ìˆ˜: 0.3699\n",
      "  - ì•Œë¯¸ê³µì› | ì ìˆ˜: 0.3592\n",
      "  - ì²­ìš´ê³µì› | ì ìˆ˜: 0.3556\n",
      "  - ë‹¹ì •ê·¼ë¦°ê³µì› | ì ìˆ˜: 0.3509\n",
      "  - ê³„ë‚¨ì œ1ê·¼ë¦°ê³µì› | ì ìˆ˜: 0.3451\n",
      "\n",
      "ğŸ“‚ Type: cafe\n",
      "  - ë™ì‘ë…¸ì„ì¹´í˜ | ì ìˆ˜: 0.4325\n",
      "  - ì—”ì ¤524 | ì ìˆ˜: 0.3832\n",
      "  - ì–´ë°˜íŠ¸ë¦¬ | ì ìˆ˜: 0.3396\n",
      "  - ì»¤í”¼ë¹ˆ í™ëŒ€ì—­ì  | ì ìˆ˜: 0.3288\n",
      "  - íˆ¬ì¸í”Œë ˆì´ìŠ¤ ì„œê°•ëŒ€ì  | ì ìˆ˜: 0.3102\n",
      "  - í•¸ë“œí”½íŠ¸í˜¸í…” | ì ìˆ˜: 0.3054\n",
      "  - ìŠ¤íƒ€ë²…ìŠ¤ ì„¼íŠ¸ëŸ´ì‹œí‹°ì  | ì ìˆ˜: 0.2995\n",
      "  - ë§ˆë…¸í•€ìµìŠ¤í”„ë ˆìŠ¤ì„œìš¸ëŒ€ì…êµ¬ì—­ì  | ì ìˆ˜: 0.2982\n",
      "  - í´ë¡œë¦¬ìŠ¤ ì‹ ì´Œë³¸ì  | ì ìˆ˜: 0.2964\n",
      "  - ì•„í”„ë¦¬ì¹´ | ì ìˆ˜: 0.2810\n",
      "\n",
      "ğŸ“‚ Type: bar\n",
      "  - ë¡œë˜ ê´€ì–‘ë™ | ì ìˆ˜: 0.3940\n",
      "  - ì¹˜ì–´ìŠ¤ì˜ë“±í¬êµ¬ì²­ì  | ì ìˆ˜: 0.3378\n",
      "  - MAG Live Club | ì ìˆ˜: 0.3176\n",
      "  - ì¬ì¦ˆí´ëŸ½ ê·¸ë£¨ë¸Œ | ì ìˆ˜: 0.3133\n",
      "  - ë¸”ë£¨ë²„ë“œ | ì ìˆ˜: 0.3040\n",
      "  - í•œê°•í˜¸í”„ | ì ìˆ˜: 0.2909\n",
      "  - ì™€ë°” | ì ìˆ˜: 0.2903\n",
      "  - ì¹ ì„±í¬ì°¨ | ì ìˆ˜: 0.2893\n",
      "  - ì¹´ìŠ¤íƒ€ìš´ | ì ìˆ˜: 0.2892\n",
      "  - ê¸€ë¨ë¼ìš´ì§€ | ì ìˆ˜: 0.2713\n",
      "\n",
      "ğŸ“‚ Type: bakery\n",
      "  - íŒŒë¦¬ë°”ê²Œëœ¨ ì„œë˜ë§ˆì„ | ì ìˆ˜: 0.3000\n",
      "  - íŒŒë¦¬ë°”ê²Œëœ¨ ì‚°ë³¸6ë‹¨ì§€ | ì ìˆ˜: 0.2951\n",
      "  - íŒŒë¦¬ë°”ê²Œëœ¨ ì›”ê³¶ì  | ì ìˆ˜: 0.2645\n",
      "  - ë˜í‚¨ êµëŒ€ë²•ì›ì  | ì ìˆ˜: 0.2635\n",
      "  - ë…¸ë¸” ê´€ê´‘ í˜¸í…” ì¸ì‚¬ë™(Noble Tourist Hotel Insadong) | ì ìˆ˜: 0.2542\n",
      "  - ëšœë ˆì¥¬ë¥´ ì•„ë¦¬ë‘ì‚¼ê±°ë¦¬ | ì ìˆ˜: 0.2529\n",
      "  - íŒŒë¦¬í¬ë¼ìƒ ì´ì´Œì  | ì ìˆ˜: 0.2404\n",
      "  - ë˜í‚¨ í™ëŒ€ì—­ì  | ì ìˆ˜: 0.2384\n",
      "  - ê·¸ëœë“œí•˜ì–íŠ¸ì„œìš¸ ë¸ë¦¬ | ì ìˆ˜: 0.2328\n",
      "  - íŒŒë¦¬ë°”ê²Œëœ¨ ê³„ì–‘êµ¬ì²­ì  | ì ìˆ˜: 0.2116\n",
      "\n",
      "ğŸ“‚ Type: restaurant\n",
      "  - ë°°ìŠ¤í‚¨ë¼ë¹ˆìŠ¤ êµ¬ë¡œê³ ì²™ | ì ìˆ˜: 0.3248\n",
      "  - í•¸ë“œí”½íŠ¸í˜¸í…” | ì ìˆ˜: 0.3054\n",
      "  - ë¶€ì–´ì¹˜í‚¨ | ì ìˆ˜: 0.2902\n",
      "  - ë³¸ì£½ ì˜ë“±í¬ì‹œì¥ë¡œí„°ë¦¬ì  | ì ìˆ˜: 0.2684\n",
      "  - ìœ ì§„ì°¸ì¹˜ | ì ìˆ˜: 0.2606\n",
      "  - ì¹˜í‚¨ë§¤ë‹ˆì•„ ì˜ë“±í¬ì—­ì  | ì ìˆ˜: 0.2579\n",
      "  - ì‚¿ë½€ë¡œ ëª©ë™ì  | ì ìˆ˜: 0.2348\n",
      "  - ìŠ¤ë¬´ë””í‚¹ ì˜ë“±í¬íƒ€ì„ìŠ¤í€˜ì–´ì  | ì ìˆ˜: 0.2347\n",
      "  - í•œì¼ê´€ íƒ€ì„ìŠ¤í€˜ì–´ì  | ì ìˆ˜: 0.2305\n",
      "  - í”¼ìë‚˜ë¼ì¹˜í‚¨ê³µì£¼ êµ¬ë¡œ1í˜¸ì  | ì ìˆ˜: 0.2293\n",
      "\n",
      "ğŸ“‚ Type: shopping_mall\n",
      "  - ë§¥ìŠ¤ì—”ì˜ | ì ìˆ˜: 0.3732\n",
      "  - TOUCH | ì ìˆ˜: 0.2830\n",
      "  - ë”ìŠˆíŠ¸í•˜ìš°ìŠ¤ ì˜ë“±í¬í™ˆí”ŒëŸ¬ìŠ¤ | ì ìˆ˜: 0.2773\n",
      "  - ì„¸ì • íƒ€ì„ìŠ¤í€˜ì–´ì§€ì  | ì ìˆ˜: 0.2594\n",
      "  - ë””ì˜¤ìŠ¤ì¸ê°¤ëŸ¬ë¦¬ | ì ìˆ˜: 0.2426\n",
      "  - ì•ˆì–‘ì¶•í˜‘ì¶•ì‚°ë¬¼íŒë§¤ì¥ | ì ìˆ˜: 0.1957\n",
      "  - YA | ì ìˆ˜: 0.1711\n",
      "  - ì¿ ì•„ ì‹ ì„¸ê³„ì˜ë“±í¬ì§€ìƒA | ì ìˆ˜: 0.0668\n",
      "  - ê¸ˆí™”ì£¼ë‹¨ | ì ìˆ˜: 0.0650\n",
      "  - ì²œì‚¬ë“¤ì˜í•©ì°½ | ì ìˆ˜: 0.0535\n"
     ]
    }
   ],
   "source": [
    "# 1. ì„ í˜¸ í‚¤ì›Œë“œ í‰ê·  ì„ë² ë”©\n",
    "hope_embeddings = [get_sbert_embedding(k) for k in keyword_hope if k]\n",
    "if hope_embeddings:\n",
    "    hope_mean_vector = np.mean(hope_embeddings, axis=0)\n",
    "else:\n",
    "    hope_mean_vector = np.zeros(model.get_sentence_embedding_dimension())\n",
    "\n",
    "# 2. ë¹„ì„ í˜¸ í‚¤ì›Œë“œ í‰ê·  ì„ë² ë”©\n",
    "nonhope_embeddings = [get_sbert_embedding(k) for k in keyword_nonhope if k]\n",
    "if nonhope_embeddings:\n",
    "    nonhope_mean_vector = np.mean(nonhope_embeddings, axis=0)\n",
    "else:\n",
    "    nonhope_mean_vector = np.zeros(model.get_sentence_embedding_dimension())\n",
    "\n",
    "# 3. ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜ (í´ëŸ¬ìŠ¤í„° ëŒ€ì‹  ë‹¨ì¼ ë²¡í„° ê¸°ì¤€)\n",
    "def compute_hope_score(review_vector, name_vector, hope_mean_vector, alpha=0.2):\n",
    "    sim_review = (\n",
    "        cosine_similarity([review_vector], [hope_mean_vector])[0][0]\n",
    "        if np.linalg.norm(review_vector) > 0 and np.linalg.norm(hope_mean_vector) > 0\n",
    "        else 0.0\n",
    "    )\n",
    "    sim_name = (\n",
    "        cosine_similarity([name_vector], [hope_mean_vector])[0][0]\n",
    "        if np.linalg.norm(name_vector) > 0 and np.linalg.norm(hope_mean_vector) > 0\n",
    "        else 0.0\n",
    "    )\n",
    "    score = (1 - alpha) * sim_review + alpha * sim_name\n",
    "    return round(score, 4)\n",
    "\n",
    "# 4. ëª¨ë“  ì¥ì†Œì— ëŒ€í•´ ì ìˆ˜ ê³„ì‚°\n",
    "for place in all_places:\n",
    "    review_vec = place.get(\"review_vector\")\n",
    "    name_vec = get_sbert_embedding(place.get(\"name\", \"\"))\n",
    "    if review_vec is not None:\n",
    "        place[\"hope_score\"] = compute_hope_score(\n",
    "            review_vec, name_vec, hope_mean_vector, alpha=0.2\n",
    "        )\n",
    "\n",
    "# 5. íƒ€ì…ë³„ ì •ë ¬ ë° ì¶œë ¥\n",
    "type_grouped = defaultdict(list)\n",
    "for place in all_places:\n",
    "    if \"hope_score\" in place:\n",
    "        type_grouped[place[\"type\"]].append(place)\n",
    "\n",
    "for place_type, places in type_grouped.items():\n",
    "    print(f\"\\nğŸ“‚ Type: {place_type}\")\n",
    "    sorted_places = sorted(places, key=lambda x: x[\"hope_score\"], reverse=True)\n",
    "    for p in sorted_places[:10]:\n",
    "        print(f\"  - {p['name']} | ì ìˆ˜: {p['hope_score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecce99a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ë¹„ì„ í˜¸ í‚¤ì›Œë“œ ìœ ì‚¬ë„ (íƒ€ì…ë³„ ìƒìœ„ 3ê°œì”©):\n",
      "\n",
      "ğŸ”¹ Tourist_Attraction:\n",
      "1. ì„œì‚¼ë¦‰\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3907 | í‰ì : 4.1 | ë¦¬ë·° ìˆ˜: 822\n",
      "2. ì•Œë¯¸ê³µì›\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3881 | í‰ì : 4 | ë¦¬ë·° ìˆ˜: 234\n",
      "3. ë§¤í™”ê·¼ë¦°ê³µì›\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3765 | í‰ì : 4.1 | ë¦¬ë·° ìˆ˜: 29\n",
      "4. ê¸ˆì²œêµ\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3551 | í‰ì : 3.9 | ë¦¬ë·° ìˆ˜: 171\n",
      "5. ë…¸ë¸” ê´€ê´‘ í˜¸í…” ì¸ì‚¬ë™(Noble Tourist Hotel Insadong)\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3265 | í‰ì : 4.1 | ë¦¬ë·° ìˆ˜: 210\n",
      "6. ê³ ì‚°ìêµ\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3245 | í‰ì : 4 | ë¦¬ë·° ìˆ˜: 46\n",
      "7. ë¬µì •ê³µì›\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3187 | í‰ì : 3.9 | ë¦¬ë·° ìˆ˜: 85\n",
      "8. ê±´ì§€ê³µì›\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3168 | í‰ì : 4 | ë¦¬ë·° ìˆ˜: 273\n",
      "9. ê´‘í™”ë¬¸ê´‘ì¥\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3136 | í‰ì : 4.5 | ë¦¬ë·° ìˆ˜: 13368\n",
      "10. ê¸ˆì•”ë¬¸í™”ê³µì›\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3111 | í‰ì : 4 | ë¦¬ë·° ìˆ˜: 243\n",
      "\n",
      "ğŸ”¹ Cafe:\n",
      "1. ì‹ ì´Œë¯¸í”Œ\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.4241 | í‰ì : 4.1 | ë¦¬ë·° ìˆ˜: 91\n",
      "2. ë‹¤ê²½í–¥ì‹¤\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.4044 | í‰ì : 4.4 | ë¦¬ë·° ìˆ˜: 7\n",
      "3. ì–´ë°˜íŠ¸ë¦¬\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.4031 | í‰ì : 4 | ë¦¬ë·° ìˆ˜: 1\n",
      "4. ì»¤í”¼ë¹ˆ í™ëŒ€ì—­ì \n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3678 | í‰ì : 4 | ë¦¬ë·° ìˆ˜: 557\n",
      "5. ëª…ë™ì‚¬ì£¼ì¹´í˜ ì‹ ë¹„ì•ˆ å \n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3527 | í‰ì : 3.9 | ë¦¬ë·° ìˆ˜: 27\n",
      "6. í´ë¡œë¦¬ìŠ¤ ì‹ ì´Œë³¸ì \n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3501 | í‰ì : 4.4 | ë¦¬ë·° ìˆ˜: 361\n",
      "7. ì•„ë¦¬ìŠ¤íƒ€ì»¤í”¼ ë“±ì´Œì \n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3416 | í‰ì : 3.7 | ë¦¬ë·° ìˆ˜: 14\n",
      "8. ë¡œì¦ˆë²„ë“œêµ­ì„¸ì²­ì \n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3367 | í‰ì : 3.6 | ë¦¬ë·° ìˆ˜: 5\n",
      "9. í•¸ë“œí”½íŠ¸í˜¸í…”\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3290 | í‰ì : 4.1 | ë¦¬ë·° ìˆ˜: 599\n",
      "10. ë¹„í•˜ì¸ë“œ\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3274 | í‰ì : 4.3 | ë¦¬ë·° ìˆ˜: 63\n",
      "\n",
      "ğŸ”¹ Bar:\n",
      "1. ë¸”ë£¨ë²„ë“œ\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.4519 | í‰ì : 4.6 | ë¦¬ë·° ìˆ˜: 5\n",
      "2. ë…¸ë¸”ë”°ë¸”\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.4179 | í‰ì : 4.5 | ë¦¬ë·° ìˆ˜: 6\n",
      "3. ì™€ë°”\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.4101 | í‰ì : 3.6 | ë¦¬ë·° ìˆ˜: 16\n",
      "4. ì²œê°•ì—ë¹„ì¹œë‹¬\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3833 | í‰ì : 4.5 | ë¦¬ë·° ìˆ˜: 78\n",
      "5. MAG Live Club\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3710 | í‰ì : 3.7 | ë¦¬ë·° ìˆ˜: 3\n",
      "6. ì™€ë¼ì™€ë¼\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3600 | í‰ì : 3.6 | ë¦¬ë·° ìˆ˜: 114\n",
      "7. ê¸€ë¨ë¼ìš´ì§€\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3439 | í‰ì : 4.1 | ë¦¬ë·° ìˆ˜: 549\n",
      "8. íˆ¬ë‹¤ë¦¬ êµ¬ë¡œì—­ì \n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3213 | í‰ì : 4.1 | ë¦¬ë·° ìˆ˜: 22\n",
      "9. í”„ë£¨ì¸  ëŒ€í•™ë¡œì \n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3132 | í‰ì : 4.2 | ë¦¬ë·° ìˆ˜: 49\n",
      "10. ë¡œë˜ ê´€ì–‘ë™\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3090 | í‰ì : 3.5 | ë¦¬ë·° ìˆ˜: 12\n",
      "\n",
      "ğŸ”¹ Bakery:\n",
      "1. ë˜í‚¨ í™ëŒ€ì—­ì \n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3713 | í‰ì : 3.9 | ë¦¬ë·° ìˆ˜: 159\n",
      "2. ë˜í‚¨ êµëŒ€ë²•ì›ì \n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3435 | í‰ì : 3.9 | ë¦¬ë·° ìˆ˜: 64\n",
      "3. ë…¸ë¸” ê´€ê´‘ í˜¸í…” ì¸ì‚¬ë™(Noble Tourist Hotel Insadong)\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3265 | í‰ì : 4.1 | ë¦¬ë·° ìˆ˜: 210\n",
      "4. ë¦¬ë‚˜ìŠ¤ ìˆ­ë¡€ë¬¸ì \n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3059 | í‰ì : 3.9 | ë¦¬ë·° ìˆ˜: 54\n",
      "5. ë˜í‚¨ë„ë„ˆì¸  êµ¬ë¡œíƒœí‰ì–‘ë¬¼ì‚°ì \n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.2919 | í‰ì : 3.7 | ë¦¬ë·° ìˆ˜: 59\n",
      "6. íŒŒë¦¬ë°”ê²Œëœ¨ ì„±ê°€ì‹œì¥ì \n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.2728 | í‰ì : 3.6 | ë¦¬ë·° ìˆ˜: 38\n",
      "7. íŒŒë¦¬í¬ë¼ìƒ ì´ì´Œì \n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.2720 | í‰ì : 4 | ë¦¬ë·° ìˆ˜: 402\n",
      "8. íŒŒë¦¬ë°”ê²Œëœ¨ ì„œë˜ë§ˆì„\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.2702 | í‰ì : 4.1 | ë¦¬ë·° ìˆ˜: 9\n",
      "9. íŒŒë¦¬ë°”ê²Œëœ¨ ì‚°ë³¸6ë‹¨ì§€\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.2537 | í‰ì : 3.6 | ë¦¬ë·° ìˆ˜: 5\n",
      "10. ëšœë ˆì¥¬ë¥´ ì•„ë¦¬ë‘ì‚¼ê±°ë¦¬\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.2524 | í‰ì : 4.5 | ë¦¬ë·° ìˆ˜: 4\n",
      "\n",
      "ğŸ”¹ Restaurant:\n",
      "1. ë³¸ì£½ ì˜ë“±í¬ì‹œì¥ë¡œí„°ë¦¬ì \n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3665 | í‰ì : 3.5 | ë¦¬ë·° ìˆ˜: 11\n",
      "2. ì´ë ˆ\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3315 | í‰ì : 4.8 | ë¦¬ë·° ìˆ˜: 12\n",
      "3. ë°°ìŠ¤í‚¨ë¼ë¹ˆìŠ¤ êµ¬ë¡œê³ ì²™\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3303 | í‰ì : 4.4 | ë¦¬ë·° ìˆ˜: 51\n",
      "4. í•¸ë“œí”½íŠ¸í˜¸í…”\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3290 | í‰ì : 4.1 | ë¦¬ë·° ìˆ˜: 599\n",
      "5. í•˜ë‚˜ìŠ¤ì‹œ íƒ€ì„ìŠ¤í€˜ì–´ì \n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3211 | í‰ì : 3.8 | ë¦¬ë·° ìˆ˜: 4\n",
      "6. ë¡¯ë°ë¦¬ì•„ êµ¬ë¡œì‹œì¥ì \n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3129 | í‰ì : 3.6 | ë¦¬ë·° ìˆ˜: 321\n",
      "7. ì˜¤ëª©ì§‘ ëª©ë™ë³¸ì \n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.2981 | í‰ì : 4.2 | ë¦¬ë·° ìˆ˜: 421\n",
      "8. í•œì¼ê´€ íƒ€ì„ìŠ¤í€˜ì–´ì \n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.2942 | í‰ì : 4 | ë¦¬ë·° ìˆ˜: 410\n",
      "9. í”¼ìë‚˜ë¼ì¹˜í‚¨ê³µì£¼ êµ¬ë¡œ1í˜¸ì \n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.2681 | í‰ì : 3.5 | ë¦¬ë·° ìˆ˜: 15\n",
      "10. í”¼ììŠ¤ì¿¨ ì˜ë“±í¬ë‚¨ë¶€ì—­ì \n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.2624 | í‰ì : 4.5 | ë¦¬ë·° ìˆ˜: 72\n",
      "\n",
      "ğŸ”¹ Shopping_Mall:\n",
      "1. ë””ì˜¤ìŠ¤ì¸ê°¤ëŸ¬ë¦¬\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.3914 | í‰ì : 4.2 | ë¦¬ë·° ìˆ˜: 6\n",
      "2. TOUCH\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.2929 | í‰ì : 3.6 | ë¦¬ë·° ìˆ˜: 5\n",
      "3. YA\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.2805 | í‰ì : 5 | ë¦¬ë·° ìˆ˜: 1\n",
      "4. ë§¥ìŠ¤ì—”ì˜\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.2804 | í‰ì : 3.8 | ë¦¬ë·° ìˆ˜: 13\n",
      "5. ì„¸ì • íƒ€ì„ìŠ¤í€˜ì–´ì§€ì \n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.2637 | í‰ì : 4 | ë¦¬ë·° ìˆ˜: 3\n",
      "6. ê¸ˆí™”ì£¼ë‹¨\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.2628 | í‰ì : 3.8 | ë¦¬ë·° ìˆ˜: 4\n",
      "7. ë”ìŠˆíŠ¸í•˜ìš°ìŠ¤ ì˜ë“±í¬í™ˆí”ŒëŸ¬ìŠ¤\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.2534 | í‰ì : 3.6 | ë¦¬ë·° ìˆ˜: 27\n",
      "8. ì²œì‚¬ë“¤ì˜í•©ì°½\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.2291 | í‰ì : 4.3 | ë¦¬ë·° ìˆ˜: 3\n",
      "9. ì„±ì¼ë§ˆíŠ¸\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.2012 | í‰ì : 4 | ë¦¬ë·° ìˆ˜: 4\n",
      "10. ì•ˆì–‘ì¶•í˜‘ì¶•ì‚°ë¬¼íŒë§¤ì¥\n",
      "ë¹„ì„ í˜¸ ìœ ì‚¬ë„: 0.1834 | í‰ì : 4.8 | ë¦¬ë·° ìˆ˜: 10\n"
     ]
    }
   ],
   "source": [
    "# ì´ë¦„ê³¼ ë¦¬ë·°ë¥¼ í•¨ê»˜ ê³ ë ¤í•œ ë²¡í„° (ê°€ì¤‘ì¹˜ ì¡°ì ˆ ê°€ëŠ¥)\n",
    "def get_combined_place_vector(place, review_weight=1.0, name_weight=1.0):\n",
    "    review_vec = place.get(\"review_vector\", np.zeros(model.get_sentence_embedding_dimension()))\n",
    "    name_vec = get_sbert_embedding(place.get(\"name\", \"\"))\n",
    "    \n",
    "    if np.linalg.norm(review_vec) == 0 and np.linalg.norm(name_vec) == 0:\n",
    "        return np.zeros(model.get_sentence_embedding_dimension())\n",
    "    \n",
    "    total_weight = review_weight + name_weight\n",
    "    return (review_weight * review_vec + name_weight * name_vec) / total_weight\n",
    "\n",
    "# ì¥ì†Œë³„ ë¹„ì„ í˜¸ ìœ ì‚¬ë„ ê³„ì‚° (ì´ë¦„ í¬í•¨)\n",
    "for place in all_places:\n",
    "    combined_vec = get_combined_place_vector(place, review_weight=1.0, name_weight=1.0)\n",
    "    if np.linalg.norm(combined_vec) > 0 and np.linalg.norm(nonhope_mean_vector) > 0:\n",
    "        score = cosine_similarity([combined_vec], [nonhope_mean_vector])[0][0]\n",
    "        place[\"nonhope_score\"] = round(score, 4)\n",
    "    else:\n",
    "        place[\"nonhope_score\"] = 0.0\n",
    "\n",
    "# íƒ€ì…ë³„ë¡œ ê·¸ë£¹í™” ë° ì¶œë ¥\n",
    "type_to_places = defaultdict(list)\n",
    "for place in all_places:\n",
    "    type_to_places[place[\"type\"]].append(place)\n",
    "\n",
    "print(\"\\në¹„ì„ í˜¸ í‚¤ì›Œë“œ ìœ ì‚¬ë„ (íƒ€ì…ë³„ ìƒìœ„ 3ê°œì”©):\")\n",
    "for place_type, places in type_to_places.items():\n",
    "    print(f\"\\nğŸ”¹ {place_type.title()}:\")\n",
    "    top_places = sorted(places, key=lambda x: x[\"nonhope_score\"], reverse=True)[:10]\n",
    "    for i, place in enumerate(top_places, 1):\n",
    "        print(f\"{i}. {place['name']}\")\n",
    "        print(f\"ë¹„ì„ í˜¸ ìœ ì‚¬ë„: {place['nonhope_score']:.4f} | í‰ì : {place['rating']} | ë¦¬ë·° ìˆ˜: {place['user_ratings_total']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43834683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì €ì¥ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def convert_place_for_json(place):\n",
    "    p = place.copy()\n",
    "    \n",
    "    # review_vectorëŠ” ì €ì¥í•˜ì§€ ì•ŠìŒ\n",
    "    p.pop(\"review_vector\", None)\n",
    "\n",
    "    # name_vectorëŠ” numpyì¼ ê²½ìš° ë³€í™˜\n",
    "    if isinstance(p.get(\"name_vector\"), np.ndarray):\n",
    "        p[\"name_vector\"] = p[\"name_vector\"].tolist()\n",
    "\n",
    "    if \"cluster_scores\" in p:\n",
    "        p[\"cluster_scores\"] = list(map(float, p[\"cluster_scores\"]))\n",
    "    if \"nonhope_score\" in p:\n",
    "        p[\"nonhope_score\"] = float(p[\"nonhope_score\"])\n",
    "    \n",
    "    return p\n",
    "\n",
    "for place in all_places:\n",
    "    place[\"in_timetable\"] = False\n",
    "\n",
    "json_ready = [convert_place_for_json(p) for p in all_places]\n",
    "\n",
    "with open(\"all_places_embedding.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json_ready, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"ì €ì¥ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3521109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_places_embedding.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    all_places = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "11d4b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_ranges(all_places):\n",
    "    hope_scores = [place[\"hope_score\"] for place in all_places if \"hope_score\" in place]\n",
    "    nonhope_scores = [place[\"nonhope_score\"] for place in all_places if \"nonhope_score\" in place]\n",
    "\n",
    "    if not hope_scores or not nonhope_scores:\n",
    "        return None  # ë°ì´í„°ê°€ ì—†ì„ ê²½ìš°\n",
    "\n",
    "    return {\n",
    "        \"hope\": {\n",
    "            \"min\": min(hope_scores),\n",
    "            \"max\": max(hope_scores)\n",
    "        },\n",
    "        \"nonhope\": {\n",
    "            \"min\": min(nonhope_scores),\n",
    "            \"max\": max(nonhope_scores)\n",
    "        }\n",
    "    }\n",
    "\n",
    "# ë¶„ë‹¨ìœ„ ì‹œê°„ ì°¨ì´ ê³„ì‚° í•¨ìˆ˜\n",
    "def time_diff_minutes(t1, t2):\n",
    "    dt1 = datetime.combine(datetime.today(), t1)\n",
    "    dt2 = datetime.combine(datetime.today(), t2)\n",
    "    return abs((dt1 - dt2).total_seconds() / 60)\n",
    "\n",
    "time_table = []\n",
    "\n",
    "class ScheduleItem:\n",
    "    def __init__(self, title, start, end, place_type, location_info=None):\n",
    "        self.title = title #ì§€ì—­ ì´ë¦„\n",
    "        self.start = start  # ì‹œì‘ì‹œê°„\n",
    "        self.end = end      # ì¢…ë£Œì‹œê°„\n",
    "        self.place_type = place_type #ëª…ì†Œ, ì¹´í˜, \n",
    "        self.location_info = location_info  #ìœ„ë„, ê²½ë„\n",
    "        \n",
    "def generate_empty_slots(time_table, day_start=time(9, 0), day_end=time(23, 59)):\n",
    "    empty_slots = []\n",
    "\n",
    "    def to_datetime(t):\n",
    "        return datetime.combine(datetime.today(), t)\n",
    "\n",
    "    # ì •ë ¬ëœ íƒ€ì„í…Œì´ë¸”ë¡œ ê°€ì •\n",
    "    sorted_table = sorted(time_table, key=lambda x: x.start)\n",
    "\n",
    "    # Step 1. ì²˜ìŒ ~ ì²« ì¼ì • ì „ êµ¬ê°„\n",
    "    if not sorted_table or sorted_table[0].start > day_start:\n",
    "        empty_slots += split_empty_range(day_start, sorted_table[0].start if sorted_table else day_end)\n",
    "\n",
    "    # Step 2. ì¼ì • ì‚¬ì´ ë¹ˆ ê³µê°„ ì°¾ê¸°\n",
    "    for i in range(len(sorted_table) - 1):\n",
    "        current_end = sorted_table[i].end\n",
    "        next_start = sorted_table[i + 1].start\n",
    "        if current_end < next_start:\n",
    "            empty_slots += split_empty_range(current_end, next_start)\n",
    "\n",
    "    # Step 3. ë§ˆì§€ë§‰ ì¼ì • ~ í•˜ë£¨ ë\n",
    "    if sorted_table and sorted_table[-1].end < day_end:\n",
    "        empty_slots += split_empty_range(sorted_table[-1].end, day_end)\n",
    "\n",
    "    return empty_slots\n",
    "\n",
    "def split_empty_range(start_time, end_time):\n",
    "    slots = []\n",
    "    dt_start = datetime.combine(datetime.today(), start_time)\n",
    "    dt_end = datetime.combine(datetime.today(), end_time)\n",
    "    gap_minutes = int((dt_end - dt_start).total_seconds() // 60)\n",
    "\n",
    "    if gap_minutes < 90:\n",
    "        return []  # ë„ˆë¬´ ì§§ìœ¼ë©´ ë¬´ì‹œ\n",
    "\n",
    "    elif gap_minutes < 120:\n",
    "        # 1ì‹œê°„ 30ë¶„ ì´ìƒ 2ì‹œê°„ ë¯¸ë§Œ â†’ í•˜ë‚˜ì˜ ìŠ¬ë¡¯\n",
    "        slots.append(ScheduleItem(None, start_time, end_time, None))\n",
    "    else:\n",
    "        # 2ì‹œê°„ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê¸°\n",
    "        dt_cursor = dt_start\n",
    "        while (dt_end - dt_cursor).total_seconds() >= 120 * 60:\n",
    "            dt_next = dt_cursor + timedelta(minutes=120)\n",
    "            slots.append(ScheduleItem(None, dt_cursor.time(), dt_next.time(), None))\n",
    "            dt_cursor = dt_next\n",
    "\n",
    "        # ë‚¨ì€ ì‹œê°„ ì²˜ë¦¬\n",
    "        remaining_minutes = int((dt_end - dt_cursor).total_seconds() // 60)\n",
    "        if 120 <= remaining_minutes <= 210:  # 2ì‹œê°„ ì´ìƒ 3ì‹œê°„ 30ë¶„ ì´í•˜ë©´ í•˜ë‚˜ë¡œ ë¬¶ê¸°\n",
    "            slots.append(ScheduleItem(None, dt_cursor.time(), dt_end.time(), None))\n",
    "        elif remaining_minutes >= 90:\n",
    "            # 1ì‹œê°„ 30ë¶„ ì´ìƒì´ë©´ ë§ˆì§€ë§‰ ìŠ¬ë¡¯ìœ¼ë¡œë„ ì¸ì •\n",
    "            slots.append(ScheduleItem(None, dt_cursor.time(), dt_end.time(), None))\n",
    "\n",
    "    return slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0f1d7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-01 (Friday) | From ì‹ ë„ë¦¼ì—­ to ë¼ë§ˆë‹¤ ì„œìš¸ ì‹ ë„ë¦¼ í˜¸í…”\n",
      "  09:00 - 10:00 | ì‹ ë„ë¦¼ì—­\n",
      "  10:00 - 12:00 | None\n",
      "  12:00 - 14:00 | None\n",
      "  14:00 - 16:00 | None\n",
      "  16:00 - 18:00 | None\n",
      "  18:00 - 20:00 | None\n",
      "  20:00 - 22:00 | None\n",
      "  22:00 - 23:00 | ë¼ë§ˆë‹¤ ì„œìš¸ ì‹ ë„ë¦¼ í˜¸í…”\n",
      "2025-08-02 (Saturday) | From ë¼ë§ˆë‹¤ ì„œìš¸ ì‹ ë„ë¦¼ í˜¸í…” to ë¼ë§ˆë‹¤ ì„œìš¸ ì‹ ë„ë¦¼ í˜¸í…”\n",
      "  08:00 - 09:00 | ë¼ë§ˆë‹¤ ì„œìš¸ ì‹ ë„ë¦¼ í˜¸í…”\n",
      "  09:00 - 11:00 | None\n",
      "  11:00 - 13:00 | None\n",
      "  13:00 - 15:00 | None\n",
      "  15:00 - 17:00 | None\n",
      "  17:00 - 19:00 | None\n",
      "  19:00 - 21:00 | None\n",
      "  21:00 - 23:00 | None\n",
      "  23:00 - 00:00 | ë¼ë§ˆë‹¤ ì„œìš¸ ì‹ ë„ë¦¼ í˜¸í…”\n",
      "2025-08-03 (Sunday) | From ë¼ë§ˆë‹¤ ì„œìš¸ ì‹ ë„ë¦¼ í˜¸í…” to ì‹ ë„ë¦¼ì—­\n",
      "  08:00 - 09:00 | ë¼ë§ˆë‹¤ ì„œìš¸ ì‹ ë„ë¦¼ í˜¸í…”\n",
      "  09:00 - 11:00 | None\n",
      "  11:00 - 13:00 | None\n",
      "  13:00 - 15:00 | None\n",
      "  15:00 - 17:00 | None\n",
      "  17:00 - 19:00 | None\n",
      "  19:00 - 21:00 | None\n",
      "  21:00 - 22:00 | ì‹ ë„ë¦¼ì—­\n"
     ]
    }
   ],
   "source": [
    "def place_location_info(place_name, api_key):\n",
    "    import requests\n",
    "\n",
    "    url = \"https://maps.googleapis.com/maps/api/place/textsearch/json\"\n",
    "    params = {\n",
    "        \"query\": place_name,\n",
    "        \"key\": api_key,\n",
    "        \"language\": \"ko\"\n",
    "    }\n",
    "\n",
    "    res = requests.get(url, params=params).json()\n",
    "    if not res.get(\"results\"):\n",
    "        return None\n",
    "\n",
    "    top_result = res[\"results\"][0]\n",
    "    return {\n",
    "        \"name\": top_result.get(\"name\"),\n",
    "        \"lat\": top_result.get(\"geometry\", {}).get(\"location\", {}).get(\"lat\"),\n",
    "        \"lng\": top_result.get(\"geometry\", {}).get(\"location\", {}).get(\"lng\")\n",
    "    }\n",
    "\n",
    "def create_empty_daily_tables(API_KEY, start_date_str, end_date_str, \n",
    "                              first_day_start_time, last_day_end_time, \n",
    "                              start_location, final_end_location,\n",
    "                              accommodation_location,\n",
    "                              default_start_time=time(9, 0), default_end_time=time(23, 0)):\n",
    "    \"\"\"\n",
    "    ì—¬í–‰ ì‹œì‘~ì¢…ë£Œ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ, í˜„ì‹¤ì ì¸ ì¡°ê±´ ë°˜ì˜:\n",
    "    - ì²«ë‚ ë§Œ ì‚¬ìš©ì ì‹œì‘ì‹œê°„/ì¥ì†Œ\n",
    "    - ë§ˆì§€ë§‰ ë‚ ë§Œ ì‚¬ìš©ì ì¢…ë£Œì‹œê°„/ì¥ì†Œ\n",
    "    - ë‚˜ë¨¸ì§€ëŠ” ìˆ™ì†Œì—ì„œ ì‹œì‘/ì¢…ë£Œ\n",
    "    \"\"\"\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\").date()\n",
    "    end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\").date()\n",
    "    num_days = (end_date - start_date).days + 1\n",
    "\n",
    "    daily_tables = {}\n",
    "    table_place_info = {}\n",
    "\n",
    "    for i in range(num_days):\n",
    "        date = start_date + timedelta(days=i)\n",
    "        date_str = date.strftime(\"%Y-%m-%d\")\n",
    "        weekday = date.strftime(\"%A\")\n",
    "\n",
    "        is_first_day = i == 0\n",
    "        is_last_day = i == (num_days - 1)\n",
    "\n",
    "        # ì‹œê°„ ì„¤ì •\n",
    "        start_time = first_day_start_time if is_first_day else default_start_time\n",
    "        end_time = last_day_end_time if is_last_day else default_end_time\n",
    "\n",
    "        # ìœ„ì¹˜ ì„¤ì •\n",
    "        start_loc = start_location if is_first_day else accommodation_location\n",
    "        end_loc = final_end_location if is_last_day else accommodation_location\n",
    "\n",
    "        # ë¹ˆ ìŠ¬ë¡¯ ìƒì„±\n",
    "        slots = split_empty_range(start_time, end_time)\n",
    "\n",
    "        table_place_info[\"ì‹œì‘ìœ„ì¹˜\"] = place_location_info(start_location, API_KEY)\n",
    "        table_place_info[\"ì¢…ë£Œìœ„ì¹˜\"] = place_location_info(final_end_location, API_KEY)\n",
    "        table_place_info[\"ìˆ™ì†Œ\"] = place_location_info(accommodation_location, API_KEY)\n",
    "\n",
    "        start_loc = table_place_info[\"ì‹œì‘ìœ„ì¹˜\"][\"name\"] if is_first_day else table_place_info[\"ìˆ™ì†Œ\"][\"name\"]\n",
    "        end_loc = table_place_info[\"ì¢…ë£Œìœ„ì¹˜\"][\"name\"] if is_last_day else table_place_info[\"ìˆ™ì†Œ\"][\"name\"]\n",
    "\n",
    "        daily_tables[date_str] = {\n",
    "            \"weekday\": weekday,\n",
    "            \"start_location\": start_loc,\n",
    "            \"end_location\": end_loc,\n",
    "            \"schedule\": slots\n",
    "        }\n",
    "\n",
    "    return table_place_info, daily_tables\n",
    "\n",
    "API_KEY = \"AIzaSyBEl50H0xV7SnyNwcc0Yo-Ru-iiTXTBePc\"\n",
    "\n",
    "table_place_info, tables = create_empty_daily_tables(\n",
    "    API_KEY,\n",
    "    start_date_str=\"2025-08-01\",\n",
    "    end_date_str=\"2025-08-03\",\n",
    "    first_day_start_time=time(10, 0),\n",
    "    last_day_end_time=time(21, 0),\n",
    "    start_location=\"ì‹ ë„ë¦¼ì—­\",\n",
    "    final_end_location=\"ì‹ ë„ë¦¼ì—­\",\n",
    "    accommodation_location=\"ì‹ ë„ë¦¼ ìˆ™ì†Œ\"\n",
    ")\n",
    "\n",
    "def insert_initial_schedule_items_dynamic(daily_tables, table_place_info):\n",
    "    \"\"\"\n",
    "    ì¼ì • í…Œì´ë¸”ì— ì‹œì‘ ì „/ì¢…ë£Œ í›„ ì„ì˜ ì¼ì • ì‚½ì…\n",
    "    - ì‹œì‘ ì „: start_time ê¸°ì¤€, 1ì‹œê°„ ì „ ì¼ì •\n",
    "    - ì¢…ë£Œ í›„: end_time ê¸°ì¤€, 1ì‹œê°„ í›„ ì¼ì •\n",
    "    \"\"\"\n",
    "    for idx, (date, info) in enumerate(daily_tables.items()):\n",
    "        schedule = info[\"schedule\"]\n",
    "        start_time = schedule[0].start if schedule else time(9, 0)\n",
    "        end_time = schedule[-1].end if schedule else time(21, 0)\n",
    "\n",
    "        items_to_insert = []\n",
    "\n",
    "        # ì‹œì‘ ì „ ì¼ì •\n",
    "        if idx == 0:\n",
    "            # ì²«ë‚  â†’ ì¶œë°œì§€\n",
    "            title = table_place_info[\"ì‹œì‘ìœ„ì¹˜\"][\"name\"]\n",
    "            loc_info = table_place_info[\"ì‹œì‘ìœ„ì¹˜\"]\n",
    "            new_start = (datetime.combine(datetime.today(), start_time) - timedelta(hours=1)).time()\n",
    "            items_to_insert.append(ScheduleItem(title, new_start, start_time, \"start\", loc_info))\n",
    "        else:\n",
    "            # ì¤‘ê°„ë‚  or ë§ˆì§€ë§‰ë‚  â†’ ìˆ™ì†Œ\n",
    "            title = table_place_info[\"ìˆ™ì†Œ\"][\"name\"]\n",
    "            loc_info = table_place_info[\"ìˆ™ì†Œ\"]\n",
    "            new_start = (datetime.combine(datetime.today(), start_time) - timedelta(hours=1)).time()\n",
    "            items_to_insert.append(ScheduleItem(title, new_start, start_time, \"accommodation\", loc_info))\n",
    "\n",
    "        # ì¢…ë£Œ í›„ ì¼ì •\n",
    "        if idx == 0 and len(daily_tables)!=0:\n",
    "            # ì²«ë‚  â†’ ë„ì°©ì§€ (í•˜ë£¨ ë§ˆë¬´ë¦¬ìš©)\n",
    "            title = table_place_info[\"ìˆ™ì†Œ\"][\"name\"]\n",
    "            loc_info = table_place_info[\"ìˆ™ì†Œ\"]\n",
    "        elif idx == len(daily_tables) - 1:\n",
    "            # ë§ˆì§€ë§‰ë‚  â†’ ì¢…ë£Œì§€ì \n",
    "            title = table_place_info[\"ì¢…ë£Œìœ„ì¹˜\"][\"name\"]\n",
    "            loc_info = table_place_info[\"ì¢…ë£Œìœ„ì¹˜\"]\n",
    "        else:\n",
    "            # ì¤‘ê°„ë‚  â†’ ìˆ™ì†Œ\n",
    "            title = table_place_info[\"ìˆ™ì†Œ\"][\"name\"]\n",
    "            loc_info = table_place_info[\"ìˆ™ì†Œ\"]\n",
    "\n",
    "        new_end = (datetime.combine(datetime.today(), end_time) + timedelta(hours=1)).time()\n",
    "        items_to_insert.append(ScheduleItem(title, end_time, new_end, \"end\" if idx == len(daily_tables) - 1 else \"accommodation\", loc_info))\n",
    "\n",
    "        # ì‚½ì… (ì•, ë’¤ ìˆœì„œ ë³´ì¥)\n",
    "        schedule.insert(0, items_to_insert[0])\n",
    "        schedule.append(items_to_insert[1])\n",
    "    del table_place_info[\"ìˆ™ì†Œ\"][\"name\"]\n",
    "    del table_place_info[\"ì‹œì‘ìœ„ì¹˜\"][\"name\"]\n",
    "    del table_place_info[\"ì¢…ë£Œìœ„ì¹˜\"][\"name\"]\n",
    "    return daily_tables\n",
    "\n",
    "tables = insert_initial_schedule_items_dynamic(tables, table_place_info)\n",
    "\n",
    "for date, data in tables.items():\n",
    "    print(f\"{date} ({data['weekday']}) | From {data['start_location']} to {data['end_location']}\")\n",
    "    for item in data['schedule']:\n",
    "        print(f\"  {item.start.strftime('%H:%M')} - {item.end.strftime('%H:%M')} | {item.title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa8a10c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª…ì†Œ ì œì•½ ì¡°ê±´ ëŒ€ì…\n",
    "def get_constraints(base_mode=\"ëª…ì†Œ ì¤‘ì‹¬\"):\n",
    "    constraints = {\n",
    "        \"must_visit_attraction_every_minutes\": 240,  # 4ì‹œê°„ : ë§ˆì§€ë§‰ ëª…ì†Œ ë°©ë¬¸ í›„ ì¼ì • ì‹œê°„ì´ ì§€ë‚˜ë©´ ë°˜ë“œì‹œ ìƒˆë¡œìš´ ëª…ì†Œë¥¼ ì¶”ì²œí•´ì•¼ í•œë‹¤ëŠ” ì œì•½\n",
    "        \"attraction_required\": True, # í•˜ë£¨ ì¼ì •ì— ëª…ì†Œê°€ ë°˜ë“œì‹œ í¬í•¨ë˜ì–´ì•¼ í•˜ëŠ”ì§€ ì—¬ë¶€\n",
    "\n",
    "        \"min_minutes_between_meals\": 360,  # 6ì‹œê°„ : ì‹ì‚¬ í›„ ì‹ì‚¬ë¥¼ ë°˜ë“œì‹œ í•´ì•¼í•˜ëŠ” ì œì•½ ì—¬ë¶€\n",
    "        \"require_meal_after_threshold\": True, # ì‹ì‚¬ë¥¼ í•˜ì§€ ì•Šê³  ì¼ì • ì‹œê°„ì´ ì§€ë‚˜ë©´, ë‹¤ìŒ ì¼ì •ìœ¼ë¡œ ë°˜ë“œì‹œ ì‹ì‚¬ë¥¼ í¬í•¨í•´ì•¼ í•œë‹¤ëŠ” ì¡°ê±´\n",
    "        \"dont_eat_meal\": 240, #ì‹ì‚¬ í›„ ì§€ë‚˜ê°€ì•¼í•˜ëŠ” ì‹œê°„ ì—¬ë¶€\n",
    "\n",
    "        \"department_store_required_interval\": None, # ì¼ì •ì´ íŠ¹ì • ì‹œê°„(ë¶„ ë‹¨ìœ„) ì´ìƒ ì§€ë‚  ë•Œë§ˆë‹¤ ë°±í™”ì ì´ë‚˜ ì‡¼í•‘ëª°ì„ ê¼­ ì¼ì •ì— ë„£ì–´ì•¼ í•œë‹¤ëŠ” ì œì•½ ì¡°ê±´\n",
    "\n",
    "        \"allow_multiple_cafes\": False # í•˜ë£¨ ì¼ì •ì— ì¹´í˜(ë˜ëŠ” ìœ ì‚¬ ì¥ì†Œ: ë¹µì§‘ ë“±)ë¥¼ ì—°ì†ìœ¼ë¡œ í¬í•¨í•˜ëŠ” ê²ƒì„ í—ˆìš©í• ì§€ ì—¬ë¶€\n",
    "    }\n",
    "    # ì¶”ê°€ ì„ íƒ ì˜µì…˜ ë°˜ì˜\n",
    "    if base_mode ==\"ì‹ì‚¬ ì¤‘ì‹¬\": # ëª…ì†Œ í•„ìˆ˜ ì œê±°í•˜ê³  ì‹ì‚¬ ê°€ê²Œ ì œì•½ì„ 3ì‹œê°„ìœ¼ë¡œ ê°ì†Œ\n",
    "        constraints[\"attraction_required\"] = False\n",
    "        constraints[\"min_minutes_between_meals\"] = 240\n",
    "\n",
    "    if base_mode ==\"ì¹´í˜, ë¹µì§‘ ì¤‘ì‹¬\": # ì‹ì‚¬ í•„ìˆ˜ ì¡°ê±´ ì œê±°í•˜ê³  ëª…ì†Œ í•„ìˆ˜ ì œê±°, ì¹´í˜ì—°ì† í—ˆìš©\n",
    "        constraints[\"require_meal_after_threshold\"] = False\n",
    "        constraints[\"attraction_required\"] = False\n",
    "        constraints[\"allow_multiple_cafes\"] = True\n",
    "\n",
    "    if base_mode ==\"ì‡¼í•‘ ì¤‘ì‹¬\": # ëª…ì†Œì¡°ê±´ ì œê±° ë° ë°±í™”ì  ê°œìˆ˜ ì œí•œ í•´ì œ\n",
    "        constraints[\"department_store_required_interval\"] = 180  # 3ì‹œê°„ë§ˆë‹¤ ì‡¼í•‘\n",
    "        constraints[\"attraction_required\"] = False\n",
    "\n",
    "    return constraints\n",
    "\n",
    "# ì¸ë±ìŠ¤ ê¸°ì¤€ ì§€ë‚œ ìµœëŒ€ ì‹œê°„ ë°˜í™˜\n",
    "def get_elapsed_minutes_since_last_type(place_type, time_table, idx):\n",
    "    \"\"\"í˜„ì¬ ì¸ë±ìŠ¤ ê¸°ì¤€, í•´ë‹¹ íƒ€ì…(place_type)ì˜ ë§ˆì§€ë§‰ ë°©ë¬¸ìœ¼ë¡œë¶€í„° ê²½ê³¼í•œ ì‹œê°„(ë¶„)ì„ ë°˜í™˜\"\"\"\n",
    "    current_start = time_table[idx].start\n",
    "\n",
    "    # í˜„ì¬ ì´ì „ ìŠ¬ë¡¯ ì¤‘ í•´ë‹¹ íƒ€ì…ì„ ì°¾ëŠ”ë‹¤\n",
    "    for i in range(idx - 1, -1, -1):\n",
    "        if time_table[i].place_type == place_type:\n",
    "            last_end = time_table[i].end\n",
    "            return time_diff_minutes(last_end, current_start)\n",
    "\n",
    "    # í•´ë‹¹ íƒ€ì…ì´ ì•„ì˜ˆ ì—†ì—ˆìœ¼ë©´ ì²« ì¼ì • ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°\n",
    "    first_time = time_table[0].start\n",
    "    return time_diff_minutes(first_time, current_start)\n",
    "\n",
    "# íƒ€ì… ì„ íƒ í•¨ìˆ˜\n",
    "def select_allowed_types(time_table, base_mode, idx):\n",
    "    allowed_types = ['tourist_attraction', 'cafe', 'restaurant', 'bakery', 'bar', 'shopping_mall']\n",
    "\n",
    "    constraints = get_constraints(base_mode)\n",
    "\n",
    "    if constraints[\"attraction_required\"] == True:\n",
    "        if get_elapsed_minutes_since_last_type('tourist_attraction', time_table, idx) >= constraints[\"must_visit_attraction_every_minutes\"]:\n",
    "            allowed_types = ['tourist_attraction']\n",
    "            return allowed_types\n",
    "    \n",
    "    if constraints[\"require_meal_after_threshold\"] == True:\n",
    "        if get_elapsed_minutes_since_last_type('restaurant', time_table, idx)<=constraints[\"dont_eat_meal\"]:\n",
    "            allowed_types.remove(\"restaurant\")\n",
    "        if get_elapsed_minutes_since_last_type('restaurant', time_table, idx)>=constraints[\"min_minutes_between_meals\"]:\n",
    "            allowed_types = ['restaurant']\n",
    "            return allowed_types\n",
    "    \n",
    "    if constraints[\"department_store_required_interval\"] != None:\n",
    "        if get_elapsed_minutes_since_last_type('shopping_mall', time_table, idx)<=constraints[\"department_store_required_interval\"]:\n",
    "            allowed_types = ['shopping_mall']\n",
    "            return allowed_types\n",
    "    \n",
    "    if constraints[\"allow_multiple_cafes\"] == False:\n",
    "        if time_table[idx-1].place_type == \"cafe\" or time_table[idx-1].place_type == \"bakery\":\n",
    "            for t in [\"cafe\", \"bakery\"]:\n",
    "                allowed_types.remove(t)\n",
    "    \n",
    "    return allowed_types\n",
    "\n",
    "import math\n",
    "\n",
    "# ìœ í´ë¦¬ë“œ ê¸°ë°˜ ê±°ë¦¬ ê³„ì‚° í•¨ìˆ˜\n",
    "def euclidean(lat1, lon1, lat2, lon2):\n",
    "    return math.sqrt((lat1 - lat2) ** 2 + (lon1 - lon2) ** 2)\n",
    "\n",
    "# ê±°ë¦¬ ê³„ì‚° í•¨ìˆ˜\n",
    "def compute_distance(place1, place2):\n",
    "    if not place1 or not place2:\n",
    "        return float(\"inf\")\n",
    "\n",
    "    return ((place1['lat'] - place2['lat']) ** 2 + (place1['lng'] - place2['lng']) ** 2) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3346d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_korean_time(text):\n",
    "    try:\n",
    "        if \"ì˜¤ì „\" in text:\n",
    "            return datetime.strptime(text, \"ì˜¤ì „ %I:%M\").time()\n",
    "        elif \"ì˜¤í›„\" in text:\n",
    "            hour = int(text.replace(\"ì˜¤í›„ \", \"\").split(\":\")[0])\n",
    "            minute = int(text.split(\":\")[1])\n",
    "            if hour != 12:\n",
    "                hour += 12\n",
    "            return time(hour, minute)\n",
    "        else:\n",
    "            # 24ì‹œê°„ì œ ì˜ˆì™¸ ì²˜ë¦¬ (ì˜ˆ: \"10:00\")\n",
    "            return datetime.strptime(text.strip(), \"%H:%M\").time()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def is_place_open_during_slot(place, date_str, start_time, end_time):\n",
    "    if place.get(\"business_status\") != \"OPERATIONAL\":\n",
    "        return False\n",
    "\n",
    "    weekday = datetime.strptime(date_str, \"%Y-%m-%d\").weekday()\n",
    "    weekday_kr = [\"ì›”ìš”ì¼\", \"í™”ìš”ì¼\", \"ìˆ˜ìš”ì¼\", \"ëª©ìš”ì¼\", \"ê¸ˆìš”ì¼\", \"í† ìš”ì¼\", \"ì¼ìš”ì¼\"]\n",
    "    target_day = weekday_kr[weekday]\n",
    "\n",
    "    for text in place.get(\"weekday_text\", []):\n",
    "        if not text.startswith(target_day):\n",
    "            continue\n",
    "\n",
    "        # 24ì‹œê°„ ì˜ì—… ì¼€ì´ìŠ¤ ì²˜ë¦¬\n",
    "        if \"24ì‹œê°„\" in text:\n",
    "            return True\n",
    "\n",
    "        try:\n",
    "            time_range = text.split(\": \", 1)[-1].split(\" ~ \")\n",
    "            open_time = parse_korean_time(time_range[0])\n",
    "            close_time = parse_korean_time(time_range[1])\n",
    "            if not open_time or not close_time:\n",
    "                continue\n",
    "\n",
    "            # ë§ˆê° ì‹œê°„ì´ ìì • ë„˜ëŠ” ê²½ìš° ì²˜ë¦¬\n",
    "            if close_time < open_time:\n",
    "                close_time = time(23, 59)\n",
    "\n",
    "            if open_time <= start_time and end_time <= close_time:\n",
    "                return True\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return False\n",
    "\n",
    "def get_valid_candidates(all_places, allowed_types, date_str, slot):\n",
    "    candidates = []\n",
    "\n",
    "    for place in all_places:\n",
    "        if place.get(\"in_timetable\"):  # ì´ë¯¸ ê°„ ê³³ì´ë©´ ì œì™¸\n",
    "            continue\n",
    "        if \"í˜¸í…”\" in place.get(\"name\", \"\"):  # ì´ë¦„ì— 'í˜¸í…”' ë“¤ì–´ê°€ë©´ ì œì™¸\n",
    "            continue\n",
    "        if place['type'] not in allowed_types:\n",
    "            continue\n",
    "        if is_place_open_during_slot(place, date_str, slot.start, slot.end):\n",
    "            candidates.append(place)\n",
    "\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6df672ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_params(user_id, filename=\"user_params.json\"):\n",
    "    try:\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        return data.get(user_id, None)  # ì—†ìœ¼ë©´ None ë°˜í™˜\n",
    "    except FileNotFoundError:\n",
    "        print(f\"[ì˜¤ë¥˜] '{filename}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"[ì˜¤ë¥˜] '{filename}' íŒŒì¼ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "\n",
    "def compute_total_score(user_id, place, prev_location, ranges):\n",
    "    if not prev_location:\n",
    "        return -float(\"inf\")\n",
    "\n",
    "    # ì‚¬ìš©ìë³„ ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    params = get_user_params(user_id)\n",
    "    if params is None:\n",
    "        # ê¸°ë³¸ê°’ ì ìš©\n",
    "        params = {\n",
    "            \"w_dist\": 0.5,\n",
    "            \"w_cluster\": 0.4,\n",
    "            \"w_trust\": 0.4,\n",
    "            \"w_nonhope\": 0.3\n",
    "        }\n",
    "\n",
    "    # ê±°ë¦¬ ì ìˆ˜\n",
    "    dist = compute_distance(prev_location, place)\n",
    "    dist_score = 1 / (1 + dist)\n",
    "\n",
    "    # ì„ í˜¸ ìœ ì‚¬ë„ (ì •ê·œí™” í¬í•¨)\n",
    "    raw_cluster_score = place.get(\"cluster_scores\", 0.0)\n",
    "    cluster_min = ranges[\"hope\"][\"min\"]\n",
    "    cluster_max = ranges[\"hope\"][\"max\"]\n",
    "    if cluster_max > cluster_min:\n",
    "        cluster_score = (raw_cluster_score - cluster_min) / (cluster_max - cluster_min)\n",
    "    else:\n",
    "        cluster_score = 0.0\n",
    "\n",
    "    # ë¹„ì„ í˜¸ ì ìˆ˜ (ì •ê·œí™” í¬í•¨)\n",
    "    raw_nonhope_score = place.get(\"nonhope_score\", 0.0)\n",
    "    nonhope_min = ranges[\"nonhope\"][\"min\"]\n",
    "    nonhope_max = ranges[\"nonhope\"][\"max\"]\n",
    "    if nonhope_max > nonhope_min:\n",
    "        nonhope_score = (raw_nonhope_score - nonhope_min) / (nonhope_max - nonhope_min)\n",
    "    else:\n",
    "        nonhope_score = 0.0\n",
    "\n",
    "    # ì‹ ë¢°ë„\n",
    "    trust_score = place.get(\"trust_score\", 0.0)\n",
    "\n",
    "    # ì‚¬ìš©ìë³„ ê°€ì¤‘ì¹˜ ì ìš©\n",
    "    total_score = (\n",
    "        params[\"w_dist\"] * dist_score +\n",
    "        params[\"w_cluster\"] * cluster_score +\n",
    "        params[\"w_trust\"] * trust_score -\n",
    "        params[\"w_nonhope\"] * nonhope_score\n",
    "    )\n",
    "\n",
    "    return total_score\n",
    "\n",
    "\n",
    "def compute_future_reward(user_id, schedule, current_idx, all_places, date_str, ranges, depth, base_mode):\n",
    "    if depth == 0 or current_idx >= len(schedule):\n",
    "        return 0\n",
    "\n",
    "    current_slot = schedule[current_idx]\n",
    "    \n",
    "    if current_slot.title is not None:\n",
    "        future_loc = current_slot.location_info\n",
    "        prev_loc = None\n",
    "        for i in range(current_idx - 1, -1, -1):\n",
    "            if schedule[i].location_info:\n",
    "                prev_loc = schedule[i].location_info\n",
    "                break\n",
    "        if prev_loc and future_loc:\n",
    "            return compute_total_score(user_id, future_loc, prev_loc, ranges)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    allowed_types = select_allowed_types(schedule, base_mode, current_idx)\n",
    "    candidates = get_valid_candidates(all_places, allowed_types, date_str, current_slot)\n",
    "\n",
    "    prev_loc = None\n",
    "    for i in range(current_idx - 1, -1, -1):\n",
    "        if schedule[i].location_info:\n",
    "            prev_loc = schedule[i].location_info\n",
    "            break\n",
    "\n",
    "    top_candidates = sorted(candidates, key=lambda p: compute_distance(prev_loc, p))[:10]\n",
    "\n",
    "    best_reward = -float(\"inf\")\n",
    "    for place in top_candidates:\n",
    "        # ì„ì‹œ ì‚½ì…\n",
    "        schedule[current_idx].title = place[\"name\"]\n",
    "        schedule[current_idx].place_type = place[\"type\"]\n",
    "        schedule[current_idx].location_info = {\n",
    "            \"lat\": place[\"lat\"],\n",
    "            \"lng\": place[\"lng\"]\n",
    "        }\n",
    "        place[\"in_timetable\"] = True\n",
    "\n",
    "        immediate = compute_total_score(user_id, place, prev_loc, ranges)\n",
    "        future = compute_future_reward(user_id, schedule, current_idx + 1, all_places, date_str, ranges, depth - 1, base_mode)\n",
    "        total = immediate + future\n",
    "\n",
    "        if total > best_reward:\n",
    "            best_reward = total\n",
    "\n",
    "        # ë¡¤ë°±\n",
    "        schedule[current_idx].title = None\n",
    "        schedule[current_idx].place_type = None\n",
    "        schedule[current_idx].location_info = None\n",
    "        place[\"in_timetable\"] = False\n",
    "\n",
    "    return best_reward\n",
    "\n",
    "def dqn_fill_schedule(user_id, tables, all_places, base_mode=\"ëª…ì†Œ ì¤‘ì‹¬\"):\n",
    "    ranges = get_score_ranges(all_places)  # cluster, nonhope í¬í•¨\n",
    "    for date_str, info in tables.items():\n",
    "        schedule = info[\"schedule\"]\n",
    "        for idx, slot in enumerate(schedule):\n",
    "            if slot.title is not None:\n",
    "                continue\n",
    "\n",
    "            allowed_types = select_allowed_types(schedule, base_mode, idx)\n",
    "            if not allowed_types:\n",
    "                continue\n",
    "\n",
    "            candidates = get_valid_candidates(all_places, allowed_types, date_str, slot)\n",
    "            if not candidates:\n",
    "                continue\n",
    "\n",
    "            prev_loc = None\n",
    "            for i in range(idx - 1, -1, -1):\n",
    "                if schedule[i].location_info:\n",
    "                    prev_loc = schedule[i].location_info\n",
    "                    break\n",
    "\n",
    "            if prev_loc is None:\n",
    "                continue\n",
    "\n",
    "            top_candidates = sorted(candidates, key=lambda p: compute_distance(prev_loc, p))[:10]\n",
    "            if not top_candidates:\n",
    "                continue\n",
    "\n",
    "            best_score = -float(\"inf\")\n",
    "            best_place = None\n",
    "\n",
    "            for place in top_candidates:\n",
    "                immediate = compute_total_score(user_id, place, prev_loc, ranges)\n",
    "                future = compute_future_reward(\n",
    "                    user_id, schedule, idx + 1, all_places, date_str, ranges, depth=2, base_mode=base_mode\n",
    "                )\n",
    "                total = immediate + future\n",
    "\n",
    "                if total > best_score:\n",
    "                    best_score = total\n",
    "                    best_place = place\n",
    "\n",
    "            if best_place:\n",
    "                schedule[idx].title = best_place[\"name\"]\n",
    "                schedule[idx].place_type = best_place[\"type\"]\n",
    "                schedule[idx].location_info = {\n",
    "                    \"name\": best_place[\"name\"],\n",
    "                    \"lat\": best_place[\"lat\"],\n",
    "                    \"lng\": best_place[\"lng\"]\n",
    "                }\n",
    "                best_place[\"in_timetable\"] = True\n",
    "\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d6e09381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_user_profile(user_id, default_weights=None):\n",
    "    if default_weights is None:\n",
    "        default_weights = {\n",
    "            \"w_dist\": 0.5,\n",
    "            \"w_cluster\": 0.4,\n",
    "            \"w_trust\": 0.4,\n",
    "            \"w_nonhope\": 0.3\n",
    "        }\n",
    "    return {user_id: default_weights.copy()}\n",
    "\n",
    "def save_user_params_to_json(user_params, filename=\"user_params.json\"):\n",
    "    # numpy ë°°ì—´ì€ jsonìœ¼ë¡œ ë°”ë¡œ ì €ì¥í•  ìˆ˜ ì—†ìœ¼ë‹ˆ listë¡œ ë³€í™˜\n",
    "    serializable_params = {}\n",
    "    for user_id, params in user_params.items():\n",
    "        serializable_params[user_id] = {\n",
    "            key: value.tolist() if isinstance(value, np.ndarray) else value\n",
    "            for key, value in params.items()\n",
    "        }\n",
    "\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(serializable_params, f, indent=4, ensure_ascii=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d7ce5252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_travel_log(user_id, route_places, user_rating, title=\"ë‚˜ì˜ ì—¬í–‰\", filename=\"travel_logs.json\"):\n",
    "    import json\n",
    "\n",
    "    # íŒŒì¼ ì½ê¸°\n",
    "    try:\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read().strip()\n",
    "            data = json.loads(content) if content else {}\n",
    "    except FileNotFoundError:\n",
    "        data = {}\n",
    "\n",
    "    # ì‚¬ìš©ìë³„ ë¡œê·¸ ì´ˆê¸°í™”\n",
    "    if user_id not in data:\n",
    "        data[user_id] = []\n",
    "\n",
    "    # ì œëª© ì¤‘ë³µ ì²´í¬\n",
    "    existing_titles = {log.get(\"title\", \"\") for log in data[user_id]}\n",
    "    base_title = title\n",
    "    suffix = 1\n",
    "    while title in existing_titles:\n",
    "        suffix += 1\n",
    "        title = f\"{base_title} ({suffix})\"\n",
    "\n",
    "    # ì¼ì • êµ¬ì„±\n",
    "    table_data = {}\n",
    "    for date_str, info in route_places.items():\n",
    "        table_data[date_str] = {\n",
    "            \"start_location\": info[\"start_location\"],\n",
    "            \"end_location\": info[\"end_location\"],\n",
    "            \"schedule\": [\n",
    "                {\n",
    "                    \"title\": travel_place.title,\n",
    "                    \"start\": travel_place.start.strftime(\"%H:%M\"),\n",
    "                    \"end\": travel_place.end.strftime(\"%H:%M\"),\n",
    "                    \"type\": travel_place.place_type,\n",
    "                    \"location_info\": {\n",
    "                        \"lat\": travel_place.location_info[\"lat\"],\n",
    "                        \"lng\": travel_place.location_info[\"lng\"]\n",
    "                    },\n",
    "                    \"rating\": None\n",
    "                }\n",
    "                for travel_place in info[\"schedule\"]\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # ì €ì¥í•  ê°ì²´ êµ¬ì„±\n",
    "    travel_log = {\n",
    "        \"title\": title,\n",
    "        \"table\": table_data,\n",
    "        \"rating\": user_rating\n",
    "    }\n",
    "\n",
    "    # ì¶”ê°€ ë° ì €ì¥\n",
    "    data[user_id].append(travel_log)\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "089fe117",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = \"user_001\"\n",
    "\n",
    "user_params = {}\n",
    "user_params.update(init_user_profile(user_id))\n",
    "\n",
    "save_user_params_to_json(user_params)\n",
    "\n",
    "table_place_info, tables = create_empty_daily_tables(\n",
    "    API_KEY,\n",
    "    start_date_str=\"2025-08-01\",\n",
    "    end_date_str=\"2025-08-03\",\n",
    "    first_day_start_time=time(10, 0),\n",
    "    last_day_end_time=time(21, 0),\n",
    "    start_location=\"ì‹ ë„ë¦¼ì—­\",\n",
    "    final_end_location=\"ì‹ ë„ë¦¼ì—­\",\n",
    "    accommodation_location=\"ì‹ ë„ë¦¼ ìˆ™ì†Œ\"\n",
    ")\n",
    "\n",
    "tables = insert_initial_schedule_items_dynamic(tables, table_place_info)\n",
    "\n",
    "for place in all_places:\n",
    "    place[\"in_timetable\"] = False\n",
    "\n",
    "tables = dqn_fill_schedule(\n",
    "    user_id,\n",
    "    tables,\n",
    "    all_places\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f5753ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2025-08-01 | From ì‹ ë„ë¦¼ì—­ to ë¼ë§ˆë‹¤ ì„œìš¸ ì‹ ë„ë¦¼ í˜¸í…”\n",
      "  09:00 - 10:00 | ì‹ ë„ë¦¼ì—­\n",
      "  10:00 - 12:00 | ì°¸ìƒˆì–´ë¦°ì´ê³µì›\n",
      "  12:00 - 14:00 | íŒŒìŠ¤ì¿ ì°Œë³´ë¼ë§¤ê³µì›ì \n",
      "  14:00 - 16:00 | ë§‰ë‚´íšŒì„¼íƒ€\n",
      "  16:00 - 18:00 | ê²½ë³µê¶\n",
      "  18:00 - 20:00 | Nì„œìš¸íƒ€ì›Œ\n",
      "  20:00 - 22:00 | ê´‘í™”ë¬¸ê´‘ì¥\n",
      "  22:00 - 23:00 | ë¼ë§ˆë‹¤ ì„œìš¸ ì‹ ë„ë¦¼ í˜¸í…”\n",
      "\n",
      "2025-08-02 | From ë¼ë§ˆë‹¤ ì„œìš¸ ì‹ ë„ë¦¼ í˜¸í…” to ë¼ë§ˆë‹¤ ì„œìš¸ ì‹ ë„ë¦¼ í˜¸í…”\n",
      "  08:00 - 09:00 | ë¼ë§ˆë‹¤ ì„œìš¸ ì‹ ë„ë¦¼ í˜¸í…”\n",
      "  09:00 - 11:00 | ê³„ë‚¨ì œ1ê·¼ë¦°ê³µì›\n",
      "  11:00 - 13:00 | ë¶€ì²œì›ë¯¸ê³µì›\n",
      "  13:00 - 15:00 | ì‚¿ë½€ë¡œ ëª©ë™ì \n",
      "  15:00 - 17:00 | íˆ¬ì¸í”Œë ˆì´ìŠ¤ ê°€ì‚°ë””ì§€í„¸ì \n",
      "  17:00 - 19:00 | ì‚¼ë•ê³µì›\n",
      "  19:00 - 21:00 | í•™ìš´ê³µì›\n",
      "  21:00 - 23:00 | ë¡¯ë°ë¦¬ì•„ êµ¬ë¡œì‹œì¥ì \n",
      "  23:00 - 00:00 | ë¼ë§ˆë‹¤ ì„œìš¸ ì‹ ë„ë¦¼ í˜¸í…”\n",
      "\n",
      "2025-08-03 | From ë¼ë§ˆë‹¤ ì„œìš¸ ì‹ ë„ë¦¼ í˜¸í…” to ì‹ ë„ë¦¼ì—­\n",
      "  08:00 - 09:00 | ë¼ë§ˆë‹¤ ì„œìš¸ ì‹ ë„ë¦¼ í˜¸í…”\n",
      "  09:00 - 11:00 | ì»¤í”¼ë¹ˆ í™ëŒ€ì—­ì \n",
      "  11:00 - 13:00 | í•œê°•í˜¸í”„\n",
      "  13:00 - 15:00 | ë¡¯ë°ì›”ë“œ\n",
      "  15:00 - 17:00 | í•œì¼ê´€ íƒ€ì„ìŠ¤í€˜ì–´ì \n",
      "  17:00 - 19:00 | ì›íš¨ëŒ€êµ\n",
      "  19:00 - 21:00 | ë™ì‘ë…¸ì„ì¹´í˜\n",
      "  21:00 - 22:00 | ì‹ ë„ë¦¼ì—­\n"
     ]
    }
   ],
   "source": [
    "def print_schedule_tables(tables):\n",
    "    for date_str, info in tables.items():\n",
    "        print(f\"\\n{date_str} | From {info['start_location']} to {info['end_location']}\")\n",
    "        for item in info[\"schedule\"]:\n",
    "            title = item.title if item.title else \"None\"\n",
    "            print(f\"  {item.start.strftime('%H:%M')} - {item.end.strftime('%H:%M')} | {title}\")\n",
    "\n",
    "print_schedule_tables(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b7e8a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_travel_log(\"user_001\",tables,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d6433ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_user_trip(user_id, title, filename=\"travel_logs.json\"):\n",
    "    try:\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    user_trips = data.get(user_id)\n",
    "    if not user_trips:\n",
    "        print(f\"{user_id}ì— í•´ë‹¹í•˜ëŠ” ì—¬í–‰ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    # titleì— í•´ë‹¹í•˜ëŠ” ì—¬í–‰ ì°¾ê¸°\n",
    "    trip = next((t for t in user_trips if t[\"title\"] == title), None)\n",
    "    if not trip:\n",
    "        print(f\"'{title}' ì œëª©ì˜ ì—¬í–‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n'{title}' ì¼ì •ì˜ ì—¬í–‰ì„ í‰ê°€í•©ë‹ˆë‹¤.\\n\")\n",
    "\n",
    "    # ë‚ ì§œë³„ë¡œ ìˆœì°¨ í‰ê°€\n",
    "    for date, day_info in trip[\"table\"].items():\n",
    "        schedule = day_info[\"schedule\"]\n",
    "        print(f\"ë‚ ì§œ: {date}\")\n",
    "\n",
    "        # ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ ìŠ¬ë¡¯ ì œì™¸\n",
    "        for i, slot in enumerate(schedule):\n",
    "            if i == 0 or i == len(schedule) - 1:\n",
    "                continue\n",
    "\n",
    "            slot_title = slot.get(\"title\")\n",
    "            if not slot_title or slot_title in [\"\", \"ì¶œë°œì§€\", \"ë„ì°©ì§€\"]:\n",
    "                continue\n",
    "\n",
    "            print(f\" - ì¥ì†Œ: {slot_title} ({slot['start']} ~ {slot['end']})\")\n",
    "            while True:\n",
    "                try:\n",
    "                    score = float(input(\"   â¤ ì´ ì¥ì†Œì˜ ë³„ì ì„ ì…ë ¥í•˜ì„¸ìš” (0~5): \"))\n",
    "                    if 0.0 <= score <= 5.0:\n",
    "                        slot[\"rating\"] = round(score, 1)\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"   0ë¶€í„° 5 ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.\")\n",
    "                except ValueError:\n",
    "                    print(\"   ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "    # ì €ì¥\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    print(\"\\ní‰ê°€ê°€ ì™„ë£Œë˜ì–´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd798e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'ë‚˜ì˜ ì—¬í–‰' ì¼ì •ì˜ ì—¬í–‰ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
      "\n",
      "ë‚ ì§œ: 2025-08-01\n",
      " - ì¥ì†Œ: ì°¸ìƒˆì–´ë¦°ì´ê³µì› (10:00 ~ 12:00)\n",
      " - ì¥ì†Œ: íŒŒìŠ¤ì¿ ì°Œë³´ë¼ë§¤ê³µì›ì  (12:00 ~ 14:00)\n",
      " - ì¥ì†Œ: ë§‰ë‚´íšŒì„¼íƒ€ (14:00 ~ 16:00)\n",
      " - ì¥ì†Œ: ê²½ë³µê¶ (16:00 ~ 18:00)\n",
      " - ì¥ì†Œ: Nì„œìš¸íƒ€ì›Œ (18:00 ~ 20:00)\n",
      " - ì¥ì†Œ: ê´‘í™”ë¬¸ê´‘ì¥ (20:00 ~ 22:00)\n",
      "ë‚ ì§œ: 2025-08-02\n",
      " - ì¥ì†Œ: ê³„ë‚¨ì œ1ê·¼ë¦°ê³µì› (09:00 ~ 11:00)\n",
      " - ì¥ì†Œ: ë¶€ì²œì›ë¯¸ê³µì› (11:00 ~ 13:00)\n",
      " - ì¥ì†Œ: ì‚¿ë½€ë¡œ ëª©ë™ì  (13:00 ~ 15:00)\n",
      " - ì¥ì†Œ: íˆ¬ì¸í”Œë ˆì´ìŠ¤ ê°€ì‚°ë””ì§€í„¸ì  (15:00 ~ 17:00)\n",
      " - ì¥ì†Œ: ì‚¼ë•ê³µì› (17:00 ~ 19:00)\n",
      " - ì¥ì†Œ: í•™ìš´ê³µì› (19:00 ~ 21:00)\n",
      " - ì¥ì†Œ: ë¡¯ë°ë¦¬ì•„ êµ¬ë¡œì‹œì¥ì  (21:00 ~ 23:00)\n",
      "ë‚ ì§œ: 2025-08-03\n",
      " - ì¥ì†Œ: ì»¤í”¼ë¹ˆ í™ëŒ€ì—­ì  (09:00 ~ 11:00)\n",
      " - ì¥ì†Œ: í•œê°•í˜¸í”„ (11:00 ~ 13:00)\n",
      " - ì¥ì†Œ: ë¡¯ë°ì›”ë“œ (13:00 ~ 15:00)\n",
      " - ì¥ì†Œ: í•œì¼ê´€ íƒ€ì„ìŠ¤í€˜ì–´ì  (15:00 ~ 17:00)\n",
      " - ì¥ì†Œ: ì›íš¨ëŒ€êµ (17:00 ~ 19:00)\n",
      " - ì¥ì†Œ: ë™ì‘ë…¸ì„ì¹´í˜ (19:00 ~ 21:00)\n",
      "\n",
      "í‰ê°€ê°€ ì™„ë£Œë˜ì–´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "rate_user_trip(user_id, \"ë‚˜ì˜ ì—¬í–‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba73c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e21a941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_schedule_path(tables):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    colors = ['red', 'blue', 'green']  # ë‚ ì§œë³„ ê²½ë¡œ ìƒ‰ìƒ\n",
    "\n",
    "    for idx, (date_str, info) in enumerate(tables.items()):\n",
    "        schedule = info[\"schedule\"]\n",
    "        color = colors[idx % len(colors)]\n",
    "\n",
    "        for i, item in enumerate(schedule):\n",
    "            loc = item.location_info\n",
    "            if not loc:\n",
    "                continue\n",
    "\n",
    "            lat = loc[\"lat\"]\n",
    "            lng = loc[\"lng\"]\n",
    "            place_type = item.place_type or \"\"\n",
    "\n",
    "            # ë§ˆì»¤ ëª¨ì–‘ ê²°ì •\n",
    "            if place_type in [\"restaurant\", \"bar\"]:\n",
    "                marker = \"*\"\n",
    "            elif place_type in [\"cafe\", \"bakery\"]:\n",
    "                marker = \"^\"\n",
    "            else:\n",
    "                marker = \"o\"\n",
    "\n",
    "            plt.plot(lng, lat, marker=marker, color=color)\n",
    "\n",
    "        # ë¼ì¸ìœ¼ë¡œ ì—°ê²°\n",
    "        lats = [item.location_info[\"lat\"] for item in schedule if item.location_info]\n",
    "        lngs = [item.location_info[\"lng\"] for item in schedule if item.location_info]\n",
    "        if lats and lngs:\n",
    "            plt.plot(lngs, lats, linestyle='-', color=color, alpha=0.5)\n",
    "\n",
    "    plt.xlabel(\"Longitude\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
